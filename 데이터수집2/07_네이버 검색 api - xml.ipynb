{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3fef48f-3e2f-4160-a665-9947739cdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311279e8-7930-4fba-910d-5541a24d212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요청 함수\n",
    "def getSource(site, start) :\n",
    "    # 해더 정보 셋팅\n",
    "    header_info = {\n",
    "        'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36',\n",
    "        'X-Naver-Client-Id' : 'opLaOk6efaoqdcpG3V8j',\n",
    "        'X-Naver-Client-Secret' : 'nvzTR4HuHt',\n",
    "    }\n",
    "    \n",
    "    # 파라미터 데이터\n",
    "    param_info = {\n",
    "        'query' : '코로나',\n",
    "        'display' : 100,\n",
    "        'start' : start,\n",
    "        'sort' : 'sim',\n",
    "    }\n",
    "    # 요청한다.\n",
    "    response = requests.get(site, headers=header_info, params=param_info)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84e9c93-e8f6-4f6d-b92d-c1bc580fded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 페이지의 데이터를 가져오는 함수\n",
    "def getData(source) :\n",
    "    # bs4 객체를 생성한다.\n",
    "    soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "    \n",
    "    data_dict = {\n",
    "        'title' : [],\n",
    "        'originallink' : [],\n",
    "        'description' : [],\n",
    "        'pubDate' : [],\n",
    "    }\n",
    "    \n",
    "    item_list = soup.select('item')\n",
    "    for item_tag in item_list:\n",
    "        # print(item_tag)\n",
    "        \n",
    "        # title\n",
    "        a1 = item_tag.select_one('title')\n",
    "        data1 = getText(a1)\n",
    "        data1 = removeChar(data1)\n",
    "        \n",
    "        # originallink\n",
    "        a2 = item_tag.select_one('originallink')\n",
    "        data2 = getText(a2)\n",
    "        \n",
    "        # description\n",
    "        a3 = item_tag.select_one('description')\n",
    "        data3 = getText(a3)\n",
    "        data3 = removeChar(data3)\n",
    "        \n",
    "        # pubDate\n",
    "        a4 = item_tag.select_one('pubDate')\n",
    "        data4 = getText(a4)\n",
    "        \n",
    "        # print(data1)\n",
    "        # print(data2)\n",
    "        # print(data3)\n",
    "        # print(data4)\n",
    "        # print('---------------------------')\n",
    "        \n",
    "        data_dict['title'].append(data1)\n",
    "        data_dict['originallink'].append(data2)\n",
    "        data_dict['description'].append(data3)\n",
    "        data_dict['pubDate'].append(data4)\n",
    "        \n",
    "    df1 = pd.DataFrame(data_dict)\n",
    "    if os.path.exists('./07_data.csv') == False :\n",
    "        df1.to_csv('./07_data.csv', encoding='utf-8-sig', index=False)\n",
    "    else :\n",
    "        df1.to_csv('./07_data.csv', encoding='utf-8-sig', index=False, header=None, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727a867d-7881-4e69-8151-7c3df694bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 내에서 웹 특수문자를 제거하는 함수\n",
    "# 다른 것들이 더 있으면 같은 방식으로 작성해주세요\n",
    "def removeChar(text) :\n",
    "    # if pd.notna(text) :\n",
    "    if pd.isna(text) == True :\n",
    "        return text\n",
    "    text = text.replace('<b>', '')\n",
    "    text = text.replace('</b>', '')\n",
    "    text = text.replace('&quot;', '\"')\n",
    "    text = text.replace('&lt;', '<')\n",
    "    text = text.replace('&gt;', '>')\n",
    "    text = text.replace('&apos;', \"'\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5b9eff-0673-4585-ad82-170a7be785db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 전달된 태그로 부터 문자열 데이터를 추출해 반환하는 함수\n",
    "def getText(tag):\n",
    "    # 태그가 없다면\n",
    "    if tag == None :\n",
    "        return np.nan\n",
    "    # 문자열을 가져온다.\n",
    "    data = tag.text.strip()\n",
    "    # 길이가 0 이라면...\n",
    "    if len(data) == 0 :\n",
    "        return np.nan\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c559b6e7-6121-409c-b15d-5ce94d7db59d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 수집중\n",
      "수집완료\n"
     ]
    }
   ],
   "source": [
    "site = 'https://openapi.naver.com/v1/search/news.xml'\n",
    "# site = 'https://openapi.naver.com/v1/search/news.json'\n",
    "\n",
    "start = 1\n",
    "# 네이버 오픈 api 에서 start는 1000이 최대므로...\n",
    "while start < 1000 :\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print(f'{start} 수집중')\n",
    "    \n",
    "    # 요청한다.\n",
    "    source = getSource(site, start)\n",
    "    # print(source)\n",
    "    \n",
    "    # 한 페이지의 데이터를 가져온다.\n",
    "    getData(source)\n",
    "    \n",
    "    # start를 100 증가시킨다.\n",
    "    start = start + 100\n",
    "print('수집완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f02cb-6b9c-429e-bea1-fe69f9ebd2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
