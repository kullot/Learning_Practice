{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d199f7f6-f14c-49d2-be90-1b6f6d6914e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대용량 행렬 데이털르 빠르게 처리하기 위한 라이브러리\n",
    "# 행렬을 가지고 하는 모든 계산을 빠르고 쉽게 처리할 수 있다.\n",
    "import numpy as np\n",
    "# ☆☆☆☆☆☆☆☆ 매우중요!! ☆☆☆☆☆☆☆☆\n",
    "# 데이터 분석, 시각화, 전처리, 가공 등등등의 작업을 할 수 있는 라이브러리\n",
    "# 데이터를 다루는 작없에서 가장 중요한 라이브러리\n",
    "# 사람이 데이터를 이해하는 과정이 제일 중요하고 pandas를 이용해 작업한다.\n",
    "import pandas as pd\n",
    "# 데이터 시각화 라이브러리\n",
    "# 가장 기본이 되는 라이브러리이고 다른 시각화 라이브러리들은\n",
    "# 내부적으로 matplotlib를 기반으로 만들어져 잇다.\n",
    "# 이에. matplotlib에 그래프에 관련된 설정을 해두면\n",
    "# 다른 라이브러리들도 영햘을 받는다.\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib를 기반으로 만든 시각화 라이브러리\n",
    "# 통계 시각화에 특화되어 있다.\n",
    "import seaborn as sns\n",
    "\n",
    "# 경고가 뜨지 않게 설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 전처리 알고리즘\n",
    "# 문자열을 숫자 라벨링 데이터로 변환한다.\n",
    "# 원본데이터로 복원하는 기능도 가지고 있다.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 데이터 표준화.\n",
    "# 데이터를 어떠한 기준으로 조정하는 기능을 가지고 있다.\n",
    "# 머신러닝 : 학습 모델의 성능 개선을 위해 사용한다.\n",
    "# 딥러닝 : 학습 시간을 줄이기 위한 용도로 사용한다.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 학습용과 검증용으로 나누는 함수\n",
    "# 평가란 학습하지 않은 데이터에 대해 얼마나 성능이 좋은가를 파악하는 과정\n",
    "# 학습용과 검증용 데이터를 나눌때 랜덤하게 섞을 수 있다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 교차검증\n",
    "# 지표를 하나만 설정할 경우\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 지표를 하나이상 설정할 경우\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 교차 검증시 데이터를 랜덤하게 섞어서 나누는 방식\n",
    "from sklearn.model_selection import KFold\n",
    "# 교차 검증시 데이터를 결과 데이터가 비슷한 비율이 될 수 있도록 나누는 방식\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 하이퍼 파리미터 튜닝\n",
    "# 학습 모델들은 이미 그 성능이 매우 훌륭하다.\n",
    "# 학습 모델에 설정되어 있는 다양한 옵션들은 널리 많이 사용하는 것들로 설정되어 있다.\n",
    "# 허나 데이터 따라서 좀더 최적화된 옵션들이 있을 수 있기 때문에\n",
    "# 하이퍼 파라미터 튜닝을 실시해야 한다.\n",
    "# 옵션으로 설정할 후보값들을 설정하여 각 값들을 교차검증을 통해서\n",
    "# 최적의 옵션의 값을 찾을 수 있도록 한다.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 평가함수 - 분류용\n",
    "# 정확도. 값 두개를 던져주고 얼마나 일치하는지 확인하는 지표\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 정밀도 : 학습 모델이 True라고 예측한 것 중에 실제 True인 비율.\n",
    "from sklearn.metrics import precision_score\n",
    "# 재현율 : 실제가 True인 것을 학습모델이 얼마나 True라고 예측했는지 비율.\n",
    "from sklearn.metrics import recall_score\n",
    "# 정밀도와 재현율을 조합한 평가 수치\n",
    "from sklearn.metrics import f1_score\n",
    "# 진짜 결과가 Positive인 것을 Positive로 예측한 비율과\n",
    "# 진짜 결과가 Negative인 것을 Positive로 잘못 예측한 비율에 대한\n",
    "# 그래프를 그리고 그 그래프의 면적을 수치화 시킨 지표\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# 분류의 평가함수는 1과 가까울수록 성능이 좋다고 판단한다.\n",
    "\n",
    "# 평가함수 - 회귀용\n",
    "# mse가 값의 scale에 따라 결과에 대한 결과가 달라질 수 잇다는 문제를 보완하기 위해서 만든 지표\n",
    "# 만약 결과데이터에 대해 표준화를 진행하고 작업을 한다면 mce만 써도 된다.\n",
    "# 값이 1에 가까울 수록 좋다.\n",
    "from sklearn.metrics import r2_score\n",
    "# 진짜 결과와 예측 결과의 오차의 면적을 구하고 면적의 평균을 구해 평가하는 지표\n",
    "# 낮을수록 좋다.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 머신러닝 알고리즘 - 분류용\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 머신러닝 알고리즘 - 회귀용\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# 시간 측정을 위한모듈\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51244f67-5bc4-4a53-9cc9-6fbb8d76fd3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 선형모델\n",
    "- 분류 : 결과데이터를 기반으로 데이터를 잘 나눌 수 있는 경계선을 찾는다.\n",
    "- 회귀 : 주어진 데이터를 일반화할 수 있는 최적의 선을 찾는다.\n",
    "- LogisticRegression : 회귀 기법을 이용해 분류를 수행하는 알고리즘. 경계선과 가장 가까운 거리의 데이터간의 거리를 최소로 하는선을 찾는다.\n",
    "- SVM(SVC) : LogisticRegression와 비슷하지만 회귀가 아닌 다른 선형 방식으로 경계선을 찾는다. 경계선과 가장 가까운 거리가 데이터간의 거리가 최대가 되는 선을 찾는다.\n",
    "- LinearRegression : 가장 기본이 되는 선형 회귀 알고리즘\n",
    "- Ridge : LinearRegression에서 발생되는 과대적합을 예방하기 위해서 규제를 추가한 선형 회귀이다.\n",
    "- Lasso : LinearRegression에서 발생되는 과대적합을 예방하기 위해서 규제를 추가한 선형 회귀이다.\n",
    "- ElsticNet : Ridge 방식과 Lasso 방식 모두를 채택하는 방식이다.\n",
    "\n",
    "### 최 근접 이웃(KNeighbors)\n",
    "- 분류 : 주변의 데이터를 보고 다수결에 의해 결과를 결정한다.\n",
    "- 회귀 : 주변 데이터의 평균을 결과로 결정한다.\n",
    "- 학습시 주어진 데이터를 학습모델에 저장하는 것만 수행한다.\n",
    "- 예측시 주변의 데이터를 보고 예측을 수행한다.\n",
    "- 학습 속도는 매우 빠르지만 데이터의 상태에 따라 결과가 나쁠 가능성이 높다.\n",
    "- 최 근접 이웃의 성능에 만족한다면 이 알고리즘이 최고이다.\n",
    "\n",
    "### 결정트리(DecisionTree)\n",
    "- 주어진 데이터를 통해 질문을 만들어 질문을 통해 결과를 예측하는 방식이다.\n",
    "- 무조건 과적합이 발생하며 분류에 비해 회귀에서 결과가 매우 않좋을 수 있다.\n",
    "\n",
    "### 앙상블\n",
    "- 다수의 학습 모델이 던지는 결과를 취합해 최종 결과를 선정하는 알고리증\n",
    "- 운영방식을 Votion이나 Bagging을 사용한다.\n",
    "- Votion : 서로 다른 알고리즘에 같은 데이터를 주어 학습하는 방식\n",
    "- Bagging : 같은 알고리즘에 다른 패턴의 데이터를 주어 학습하는 방식\n",
    "- 투표방식은 Hard Voting과 SoftVoting을 사용한다.\n",
    "- Hard Voting : 각 알고리즘이 던지는 결과를 다수결로 취합하여 최종 결과를 선정한다.\n",
    "- Soft Voting : 각 알고리즘이 던지는 결과의 확률을 취합하여 확률이 가능 높은 답을 결과로 선정한다.\n",
    "- 회귀 : mse가 낮은 알고리즘들이 던진 결과의 평균을 최종 결과로 결정한다.\n",
    "- RandomForest : 운영방식은 Bagging을 사용하고 투표방식은 SoftVoting을 사용한다.\n",
    "- 내부 알고리즘은 과적합이 발생할 확률이 매우 높은 트리를 사용한다.\n",
    "\n",
    "### Boosting\n",
    "- 앙상블 모델을 사용하지만 RandomForest가 던진 결과중 오답의 패턴을 다시 학습하는 방식을 사용한다.\n",
    "- 오답을 내는 데이터의 패턴에 대해 값을 보정하는 알고리즘이 들어간다.\n",
    "- 다른 알고리즘에 비해 속도가 엄--------------------------청 오래 걸리지만 성능이 매우 우수하다는 것을 보장 받을 수 있다.\n",
    "- GradientBoosting : 부스팅 알고리즘 중에서 성능이 좋은걸 보장받을 수 있는 알고리즘\n",
    "- AdaBoosting : GradientBoosting에 비해 좋은 성능을 보이지 못할 가능성이 높지만 상황에 따라 GradientBoosting 보다 성능이 좋은 경우가 있다.\n",
    "- LGBM : GradientBoosting이 시간이 매우 오래 걸리기 때문에 성능을 조금 낮추고 속도를 높힌 알고리즘\n",
    "- XGBoost : 내부 알고리즘을 트리나 선형을 선택할 수 있고 GPU 사용도 가능하고 부스팅 알고리즘에 대한 하이퍼 파라미터를 세분하여 미세한 성능 개선을 할 수 있도록 만든 알고리즘. 사랑해요~~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
