{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c226d85-3561-4075-86d4-be77b08de287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 경고 뜨지 않게...\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 매직명령어 => 쥬피터노트북에서 그래프 삽입 기능 \n",
    "%matplotlib inline\n",
    "# 글꼴 선명화 \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# 랜덤 모듈\n",
    "import random\n",
    "\n",
    "# 학습 모델 저장 및 복원\n",
    "import pickle\n",
    "\n",
    "# 딥러닝 라이브러리\n",
    "import tensorflow as tf\n",
    "# 신경망 모델을 관리하는 객체\n",
    "from tensorflow.keras.models import Sequential\n",
    "# 선형 회귀 레이어\n",
    "from tensorflow.keras.layers import Dense\n",
    "# 활성화 함수를 정의하는 객체\n",
    "from tensorflow.keras.layers import Activation\n",
    "# 원핫 인코딩을 수행하는 함수\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 저장된 학습모델을 복원한다.\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델을 자동 저장한다.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# 성능이 더이상 좋아지지 않을 경우 중단 시킨다.\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 평가함수\n",
    "# 분류용\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 회귀용\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 문자열 => 숫자\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 전체데이터를 학습용과 검증으로 나눈다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 랜덤시드 설정\n",
    "# 데이터를 랜덤하게 섞거나 가중치를 랜덤하게 설정하는 등..\n",
    "# 작업에서 랜덤을 적용하는 경우가 더러 있다.\n",
    "# 이에, 시드를 고정시킨다.\n",
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# 현재 프로젝트에서 GPU 메모리 사용을 필요한 만큼만 쓸 수 있도록 한다.\n",
    "# 컴퓨터에 있는 GPU 정보들을 가져온다.\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# # gpu가 있다면...\n",
    "# if len(gpus) > 0 :\n",
    "#     try :\n",
    "#         for gpu in gpus :\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     except RuntimeError as e :\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e226c09c-dfd6-44d2-bd82-8cbc19d1095e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>선수명</th>\n",
       "      <th>팀명</th>\n",
       "      <th>승</th>\n",
       "      <th>패</th>\n",
       "      <th>세</th>\n",
       "      <th>홀드</th>\n",
       "      <th>블론</th>\n",
       "      <th>경기</th>\n",
       "      <th>선발</th>\n",
       "      <th>이닝</th>\n",
       "      <th>...</th>\n",
       "      <th>홈런/9</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LOB%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>RA9-WAR</th>\n",
       "      <th>FIP</th>\n",
       "      <th>kFIP</th>\n",
       "      <th>WAR</th>\n",
       "      <th>연봉(2018)</th>\n",
       "      <th>연봉(2017)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>켈리</td>\n",
       "      <td>SK</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.342</td>\n",
       "      <td>73.7</td>\n",
       "      <td>3.60</td>\n",
       "      <td>6.91</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.62</td>\n",
       "      <td>140000</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>소사</td>\n",
       "      <td>LG</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>185.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.319</td>\n",
       "      <td>67.1</td>\n",
       "      <td>3.88</td>\n",
       "      <td>6.80</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.41</td>\n",
       "      <td>6.08</td>\n",
       "      <td>120000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>양현종</td>\n",
       "      <td>KIA</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>193.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.332</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.64</td>\n",
       "      <td>230000</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>차우찬</td>\n",
       "      <td>LG</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>175.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.298</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>6.11</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.63</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>레일리</td>\n",
       "      <td>롯데</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>187.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.323</td>\n",
       "      <td>74.1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.13</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.38</td>\n",
       "      <td>111000</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   선수명   팀명   승   패  세  홀드  블론  경기  선발     이닝  ...  홈런/9  BABIP  LOB%   ERA  \\\n",
       "0   켈리   SK  16   7  0   0   0  30  30  190.0  ...  0.76  0.342  73.7  3.60   \n",
       "1   소사   LG  11  11  1   0   0  30  29  185.1  ...  0.53  0.319  67.1  3.88   \n",
       "2  양현종  KIA  20   6  0   0   0  31  31  193.1  ...  0.79  0.332  72.1  3.44   \n",
       "3  차우찬   LG  10   7  0   0   0  28  28  175.2  ...  1.02  0.298  75.0  3.43   \n",
       "4  레일리   롯데  13   7  0   0   0  30  30  187.1  ...  0.91  0.323  74.1  3.80   \n",
       "\n",
       "   RA9-WAR   FIP  kFIP   WAR  연봉(2018)  연봉(2017)  \n",
       "0     6.91  3.69  3.44  6.62    140000     85000  \n",
       "1     6.80  3.52  3.41  6.08    120000     50000  \n",
       "2     6.54  3.94  3.82  5.64    230000    150000  \n",
       "3     6.11  4.20  4.03  4.63    100000    100000  \n",
       "4     6.13  4.36  4.31  4.38    111000     85000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 읽어온다.\n",
    "df1 = pd.read_csv('./data/picher_stats_2017.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0be05421-d123-429d-80f9-c94aba755484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>팀명</th>\n",
       "      <th>승</th>\n",
       "      <th>패</th>\n",
       "      <th>세</th>\n",
       "      <th>홀드</th>\n",
       "      <th>블론</th>\n",
       "      <th>경기</th>\n",
       "      <th>선발</th>\n",
       "      <th>이닝</th>\n",
       "      <th>삼진/9</th>\n",
       "      <th>...</th>\n",
       "      <th>홈런/9</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LOB%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>RA9-WAR</th>\n",
       "      <th>FIP</th>\n",
       "      <th>kFIP</th>\n",
       "      <th>WAR</th>\n",
       "      <th>연봉(2018)</th>\n",
       "      <th>연봉(2017)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SK</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>190.0</td>\n",
       "      <td>8.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.342</td>\n",
       "      <td>73.7</td>\n",
       "      <td>3.60</td>\n",
       "      <td>6.91</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.62</td>\n",
       "      <td>140000</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>185.1</td>\n",
       "      <td>7.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.319</td>\n",
       "      <td>67.1</td>\n",
       "      <td>3.88</td>\n",
       "      <td>6.80</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.41</td>\n",
       "      <td>6.08</td>\n",
       "      <td>120000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KIA</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>193.1</td>\n",
       "      <td>7.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.332</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.64</td>\n",
       "      <td>230000</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>175.2</td>\n",
       "      <td>8.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.298</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>6.11</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.63</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>롯데</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>187.1</td>\n",
       "      <td>7.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.323</td>\n",
       "      <td>74.1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.13</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.38</td>\n",
       "      <td>111000</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    팀명   승   패  세  홀드  블론  경기  선발     이닝  삼진/9  ...  홈런/9  BABIP  LOB%   ERA  \\\n",
       "0   SK  16   7  0   0   0  30  30  190.0  8.95  ...  0.76  0.342  73.7  3.60   \n",
       "1   LG  11  11  1   0   0  30  29  185.1  7.43  ...  0.53  0.319  67.1  3.88   \n",
       "2  KIA  20   6  0   0   0  31  31  193.1  7.36  ...  0.79  0.332  72.1  3.44   \n",
       "3   LG  10   7  0   0   0  28  28  175.2  8.04  ...  1.02  0.298  75.0  3.43   \n",
       "4   롯데  13   7  0   0   0  30  30  187.1  7.49  ...  0.91  0.323  74.1  3.80   \n",
       "\n",
       "   RA9-WAR   FIP  kFIP   WAR  연봉(2018)  연봉(2017)  \n",
       "0     6.91  3.69  3.44  6.62    140000     85000  \n",
       "1     6.80  3.52  3.41  6.08    120000     50000  \n",
       "2     6.54  3.94  3.82  5.64    230000    150000  \n",
       "3     6.11  4.20  4.03  4.63    100000    100000  \n",
       "4     6.13  4.36  4.31  4.38    111000     85000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선수 이름을 제거한다.\n",
    "df1.drop('선수명', inplace=True, axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8a9bfdb-dda2-4d4e-a399-c351395a377c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>팀명</th>\n",
       "      <th>승</th>\n",
       "      <th>패</th>\n",
       "      <th>세</th>\n",
       "      <th>홀드</th>\n",
       "      <th>블론</th>\n",
       "      <th>경기</th>\n",
       "      <th>선발</th>\n",
       "      <th>이닝</th>\n",
       "      <th>삼진/9</th>\n",
       "      <th>...</th>\n",
       "      <th>홈런/9</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LOB%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>RA9-WAR</th>\n",
       "      <th>FIP</th>\n",
       "      <th>kFIP</th>\n",
       "      <th>WAR</th>\n",
       "      <th>연봉(2018)</th>\n",
       "      <th>연봉(2017)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>190.0</td>\n",
       "      <td>8.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.342</td>\n",
       "      <td>73.7</td>\n",
       "      <td>3.60</td>\n",
       "      <td>6.91</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.62</td>\n",
       "      <td>140000</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>185.1</td>\n",
       "      <td>7.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.319</td>\n",
       "      <td>67.1</td>\n",
       "      <td>3.88</td>\n",
       "      <td>6.80</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.41</td>\n",
       "      <td>6.08</td>\n",
       "      <td>120000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>193.1</td>\n",
       "      <td>7.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.332</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.64</td>\n",
       "      <td>230000</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>175.2</td>\n",
       "      <td>8.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.298</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>6.11</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.63</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>187.1</td>\n",
       "      <td>7.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.323</td>\n",
       "      <td>74.1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.13</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.38</td>\n",
       "      <td>111000</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>62.2</td>\n",
       "      <td>4.31</td>\n",
       "      <td>...</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.355</td>\n",
       "      <td>56.9</td>\n",
       "      <td>7.76</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6.48</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>7100</td>\n",
       "      <td>8100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>59.1</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.263</td>\n",
       "      <td>65.4</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.77</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>7500</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>4.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.382</td>\n",
       "      <td>52.8</td>\n",
       "      <td>11.66</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>8.03</td>\n",
       "      <td>8.29</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>10000</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>7.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.341</td>\n",
       "      <td>73.9</td>\n",
       "      <td>5.77</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.95</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>4000</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>81.0</td>\n",
       "      <td>5.78</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.312</td>\n",
       "      <td>65.3</td>\n",
       "      <td>7.67</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>7.60</td>\n",
       "      <td>7.81</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     팀명   승   패  세  홀드  블론  경기  선발     이닝  삼진/9  ...  홈런/9  BABIP  LOB%  \\\n",
       "0     4  16   7  0   0   0  30  30  190.0  8.95  ...  0.76  0.342  73.7   \n",
       "1     2  11  11  1   0   0  30  29  185.1  7.43  ...  0.53  0.319  67.1   \n",
       "2     0  20   6  0   0   0  31  31  193.1  7.36  ...  0.79  0.332  72.1   \n",
       "3     2  10   7  0   0   0  28  28  175.2  8.04  ...  1.02  0.298  75.0   \n",
       "4     6  13   7  0   0   0  30  30  187.1  7.49  ...  0.91  0.323  74.1   \n",
       "..   ..  ..  .. ..  ..  ..  ..  ..    ...   ...  ...   ...    ...   ...   \n",
       "147   8   2   5  0   0   2  33   5   62.2  4.31  ...  1.58  0.355  56.9   \n",
       "148   0   3   2  0   0   0  25  11   59.1  4.85  ...  1.06  0.263  65.4   \n",
       "149   6   0   2  0   0   0   9   2   14.2  4.91  ...  2.45  0.382  52.8   \n",
       "150   7   0   3  0   1   0  41   0   43.2  7.63  ...  1.44  0.341  73.9   \n",
       "151   1   4   4  0   0   0  24  14   81.0  5.78  ...  2.00  0.312  65.3   \n",
       "\n",
       "       ERA  RA9-WAR   FIP  kFIP   WAR  연봉(2018)  연봉(2017)  \n",
       "0     3.60     6.91  3.69  3.44  6.62    140000     85000  \n",
       "1     3.88     6.80  3.52  3.41  6.08    120000     50000  \n",
       "2     3.44     6.54  3.94  3.82  5.64    230000    150000  \n",
       "3     3.43     6.11  4.20  4.03  4.63    100000    100000  \n",
       "4     3.80     6.13  4.36  4.31  4.38    111000     85000  \n",
       "..     ...      ...   ...   ...   ...       ...       ...  \n",
       "147   7.76    -1.21  6.21  6.48 -0.47      7100      8100  \n",
       "148   5.92     0.39  6.41  6.77 -0.49      7500      3100  \n",
       "149  11.66    -0.83  8.03  8.29 -0.61     10000     16000  \n",
       "150   5.77    -0.40  6.87  6.95 -0.70      4000      2900  \n",
       "151   7.67    -0.68  7.60  7.81 -1.01      4000      3000  \n",
       "\n",
       "[152 rows x 21 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 팀명을 숫자로 변환한다.\n",
    "encoder1 = LabelEncoder()\n",
    "df1['팀명'] = encoder1.fit_transform(df1['팀명'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "005ef8f7-ca45-4be3-bbaf-f66e5d888754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 결과로 나눈다.\n",
    "X = df1.drop('연봉(2018)', axis=1)\n",
    "y = df1['연봉(2018)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c8334f1-50fd-4300-a3d1-bd3a3019951b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04225053,  3.32457765,  1.23120199, ..., -1.06162315,\n",
       "         4.51802888,  2.74374569],\n",
       "       [-0.7977895 ,  2.02618144,  2.51300132, ..., -1.07681252,\n",
       "         4.10827019,  1.34172411],\n",
       "       [-1.55332846,  4.36329461,  0.91075216, ..., -0.86922457,\n",
       "         3.77439273,  5.34750005],\n",
       "       ...,\n",
       "       [ 0.71328843, -0.8302902 , -0.37104718, ...,  1.39399038,\n",
       "        -0.9681847 , -0.02023971],\n",
       "       [ 1.09105791, -0.8302902 , -0.05059734, ...,  0.71553221,\n",
       "        -1.03647782, -0.54499636],\n",
       "       [-1.17555898,  0.20842676,  0.26985249, ...,  1.15096059,\n",
       "        -1.27170966, -0.54099058]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 표준화\n",
    "scaler1 = StandardScaler()\n",
    "X = scaler1.fit_transform(X)\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0215266-015d-47e3-81e9-a80bacdc2275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2진 분류 옵션들\n",
    "# out_nodes = 1\n",
    "# loss_function = 'binary_crossentropy'\n",
    "# activation_function = 'sigmoid'\n",
    "\n",
    "# 다중 분류 옵션들\n",
    "# out_nodes = len(y.value_counts())\n",
    "# loss_function = 'categorical_crossentropy'\n",
    "# activation_function = 'softmax'\n",
    "\n",
    "# 회귀\n",
    "# 출력 결과를 하나만 뽑아서 Series로 나왔다면...\n",
    "# 1로 설정한다.\n",
    "if type(y) is pd.core.series.Series:\n",
    "    out_nodes = 1\n",
    "else : \n",
    "    out_nodes = y.shape[1]\n",
    "    \n",
    "loss_function = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1bb7241-19fd-4f0d-b5e2-65c8078280e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력노드의 개수\n",
    "# 입력 데이터 행 하나의 컬럼의 개수\n",
    "input_size = X.shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52b35c77-a84e-4cfe-83ac-fea0c653b2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 신경망 설계\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, input_dim=input_size))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(out_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4022a4a-e2be-43a9-9074-e0e1332e4409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                630       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 30)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                620       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 20)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,271\n",
      "Trainable params: 1,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss=loss_function, optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09fb2600-62fa-4808-9e6c-a474d3d6f47b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습모델을 저장할 경로\n",
    "path = './model/23'\n",
    "\n",
    "# 만약 폴더가 있다면 삭제한다.\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "# 폴더를 생성한다.\n",
    "os.makedirs(os.path.join(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f21ea1d-1b0c-4ec1-922f-235bdc92d053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path1 = path + '/{epoch}-{val_loss}.h5'\n",
    "path2 = path + '/best_model.h5'\n",
    "\n",
    "# 저장콜백\n",
    "call1 = ModelCheckpoint(filepath=path1, monitor='val_loss', save_best_only=True)\n",
    "call2 = ModelCheckpoint(filepath=path2, monitor='val_loss', save_best_onlu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc241493-b867-45bd-be05-723061feb04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 조기 중단\n",
    "call3 = EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10d0df6e-6fa2-4069-9266-0a8010d35e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습과 검증데이터로 나눈다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7cb2f35-1c52-4a78-8a23-ac8415f3f0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1520769280.0000 - val_loss: 484708960.0000\n",
      "Epoch 2/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1520765824.0000 - val_loss: 484707680.0000\n",
      "Epoch 3/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520762368.0000 - val_loss: 484706528.0000\n",
      "Epoch 4/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1520759168.0000 - val_loss: 484705376.0000\n",
      "Epoch 5/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1520756224.0000 - val_loss: 484704192.0000\n",
      "Epoch 6/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1520753280.0000 - val_loss: 484703104.0000\n",
      "Epoch 7/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520750592.0000 - val_loss: 484702016.0000\n",
      "Epoch 8/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1520747904.0000 - val_loss: 484700928.0000\n",
      "Epoch 9/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1520744960.0000 - val_loss: 484699872.0000\n",
      "Epoch 10/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1520742400.0000 - val_loss: 484698816.0000\n",
      "Epoch 11/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1520739968.0000 - val_loss: 484697664.0000\n",
      "Epoch 12/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1520737280.0000 - val_loss: 484696544.0000\n",
      "Epoch 13/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1520734848.0000 - val_loss: 484695456.0000\n",
      "Epoch 14/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1520732288.0000 - val_loss: 484694368.0000\n",
      "Epoch 15/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1520729856.0000 - val_loss: 484693216.0000\n",
      "Epoch 16/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1520727296.0000 - val_loss: 484692096.0000\n",
      "Epoch 17/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1520724864.0000 - val_loss: 484690976.0000\n",
      "Epoch 18/200000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1520722176.0000 - val_loss: 484689856.0000\n",
      "Epoch 19/200000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1520719744.0000 - val_loss: 484688640.0000\n",
      "Epoch 20/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1520717056.0000 - val_loss: 484687488.0000\n",
      "Epoch 21/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1520714496.0000 - val_loss: 484686304.0000\n",
      "Epoch 22/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1520711936.0000 - val_loss: 484685120.0000\n",
      "Epoch 23/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1520709376.0000 - val_loss: 484683936.0000\n",
      "Epoch 24/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1520706816.0000 - val_loss: 484682688.0000\n",
      "Epoch 25/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1520704128.0000 - val_loss: 484681408.0000\n",
      "Epoch 26/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1520701312.0000 - val_loss: 484680064.0000\n",
      "Epoch 27/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1520698368.0000 - val_loss: 484678720.0000\n",
      "Epoch 28/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1520695296.0000 - val_loss: 484677280.0000\n",
      "Epoch 29/200000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1520692224.0000 - val_loss: 484675776.0000\n",
      "Epoch 30/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1520688768.0000 - val_loss: 484674240.0000\n",
      "Epoch 31/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1520685184.0000 - val_loss: 484672608.0000\n",
      "Epoch 32/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1520681600.0000 - val_loss: 484670944.0000\n",
      "Epoch 33/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1520677760.0000 - val_loss: 484669248.0000\n",
      "Epoch 34/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520673920.0000 - val_loss: 484667488.0000\n",
      "Epoch 35/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1520669824.0000 - val_loss: 484665664.0000\n",
      "Epoch 36/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520666112.0000 - val_loss: 484663872.0000\n",
      "Epoch 37/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1520661760.0000 - val_loss: 484661984.0000\n",
      "Epoch 38/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1520657408.0000 - val_loss: 484660064.0000\n",
      "Epoch 39/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1520652800.0000 - val_loss: 484658112.0000\n",
      "Epoch 40/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1520648320.0000 - val_loss: 484656064.0000\n",
      "Epoch 41/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1520643712.0000 - val_loss: 484654016.0000\n",
      "Epoch 42/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520638848.0000 - val_loss: 484651904.0000\n",
      "Epoch 43/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1520634112.0000 - val_loss: 484649696.0000\n",
      "Epoch 44/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1520628992.0000 - val_loss: 484647488.0000\n",
      "Epoch 45/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1520623744.0000 - val_loss: 484645216.0000\n",
      "Epoch 46/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1520618496.0000 - val_loss: 484642880.0000\n",
      "Epoch 47/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520613120.0000 - val_loss: 484640512.0000\n",
      "Epoch 48/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1520607616.0000 - val_loss: 484637984.0000\n",
      "Epoch 49/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1520601728.0000 - val_loss: 484635520.0000\n",
      "Epoch 50/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520595840.0000 - val_loss: 484633024.0000\n",
      "Epoch 51/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1520589696.0000 - val_loss: 484630400.0000\n",
      "Epoch 52/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1520583296.0000 - val_loss: 484627680.0000\n",
      "Epoch 53/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1520577024.0000 - val_loss: 484624960.0000\n",
      "Epoch 54/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1520570112.0000 - val_loss: 484622080.0000\n",
      "Epoch 55/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520563328.0000 - val_loss: 484619200.0000\n",
      "Epoch 56/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1520556160.0000 - val_loss: 484616192.0000\n",
      "Epoch 57/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1520548992.0000 - val_loss: 484613216.0000\n",
      "Epoch 58/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520541312.0000 - val_loss: 484610080.0000\n",
      "Epoch 59/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1520533632.0000 - val_loss: 484606848.0000\n",
      "Epoch 60/200000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1520525952.0000 - val_loss: 484603648.0000\n",
      "Epoch 61/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1520517888.0000 - val_loss: 484600224.0000\n",
      "Epoch 62/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1520509696.0000 - val_loss: 484596896.0000\n",
      "Epoch 63/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1520501248.0000 - val_loss: 484593376.0000\n",
      "Epoch 64/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1520492416.0000 - val_loss: 484589760.0000\n",
      "Epoch 65/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1520483712.0000 - val_loss: 484586080.0000\n",
      "Epoch 66/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1520474496.0000 - val_loss: 484582304.0000\n",
      "Epoch 67/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1520465024.0000 - val_loss: 484578496.0000\n",
      "Epoch 68/200000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1520455424.0000 - val_loss: 484574560.0000\n",
      "Epoch 69/200000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1520445568.0000 - val_loss: 484570560.0000\n",
      "Epoch 70/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1520435584.0000 - val_loss: 484566368.0000\n",
      "Epoch 71/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520425088.0000 - val_loss: 484562208.0000\n",
      "Epoch 72/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520414336.0000 - val_loss: 484557824.0000\n",
      "Epoch 73/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1520403712.0000 - val_loss: 484553440.0000\n",
      "Epoch 74/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1520392448.0000 - val_loss: 484548832.0000\n",
      "Epoch 75/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1520381056.0000 - val_loss: 484544096.0000\n",
      "Epoch 76/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520369536.0000 - val_loss: 484539232.0000\n",
      "Epoch 77/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1520357504.0000 - val_loss: 484534304.0000\n",
      "Epoch 78/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1520345216.0000 - val_loss: 484529216.0000\n",
      "Epoch 79/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1520332544.0000 - val_loss: 484524032.0000\n",
      "Epoch 80/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1520319872.0000 - val_loss: 484518752.0000\n",
      "Epoch 81/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1520306304.0000 - val_loss: 484513184.0000\n",
      "Epoch 82/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1520292736.0000 - val_loss: 484507584.0000\n",
      "Epoch 83/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1520278656.0000 - val_loss: 484501824.0000\n",
      "Epoch 84/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1520264448.0000 - val_loss: 484495904.0000\n",
      "Epoch 85/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1520249600.0000 - val_loss: 484489856.0000\n",
      "Epoch 86/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1520234496.0000 - val_loss: 484483648.0000\n",
      "Epoch 87/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1520218880.0000 - val_loss: 484477280.0000\n",
      "Epoch 88/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1520203008.0000 - val_loss: 484470784.0000\n",
      "Epoch 89/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1520186624.0000 - val_loss: 484464160.0000\n",
      "Epoch 90/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1520169472.0000 - val_loss: 484457408.0000\n",
      "Epoch 91/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1520152448.0000 - val_loss: 484450464.0000\n",
      "Epoch 92/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1520134784.0000 - val_loss: 484443424.0000\n",
      "Epoch 93/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1520116864.0000 - val_loss: 484436160.0000\n",
      "Epoch 94/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1520098304.0000 - val_loss: 484428768.0000\n",
      "Epoch 95/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1520079360.0000 - val_loss: 484421248.0000\n",
      "Epoch 96/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1520060032.0000 - val_loss: 484413504.0000\n",
      "Epoch 97/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1520040448.0000 - val_loss: 484405600.0000\n",
      "Epoch 98/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1520020224.0000 - val_loss: 484397504.0000\n",
      "Epoch 99/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1519999616.0000 - val_loss: 484389344.0000\n",
      "Epoch 100/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1519978752.0000 - val_loss: 484380896.0000\n",
      "Epoch 101/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1519957248.0000 - val_loss: 484372256.0000\n",
      "Epoch 102/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1519935232.0000 - val_loss: 484363488.0000\n",
      "Epoch 103/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1519912704.0000 - val_loss: 484354432.0000\n",
      "Epoch 104/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1519889536.0000 - val_loss: 484345280.0000\n",
      "Epoch 105/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1519866112.0000 - val_loss: 484335904.0000\n",
      "Epoch 106/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1519842176.0000 - val_loss: 484326400.0000\n",
      "Epoch 107/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1519817344.0000 - val_loss: 484316640.0000\n",
      "Epoch 108/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1519792256.0000 - val_loss: 484306624.0000\n",
      "Epoch 109/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1519766656.0000 - val_loss: 484296448.0000\n",
      "Epoch 110/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1519740416.0000 - val_loss: 484286048.0000\n",
      "Epoch 111/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1519713536.0000 - val_loss: 484275424.0000\n",
      "Epoch 112/200000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1519686144.0000 - val_loss: 484264576.0000\n",
      "Epoch 113/200000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1519658112.0000 - val_loss: 484253504.0000\n",
      "Epoch 114/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1519629696.0000 - val_loss: 484242240.0000\n",
      "Epoch 115/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1519600384.0000 - val_loss: 484230752.0000\n",
      "Epoch 116/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1519570560.0000 - val_loss: 484218944.0000\n",
      "Epoch 117/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1519540224.0000 - val_loss: 484206976.0000\n",
      "Epoch 118/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1519508992.0000 - val_loss: 484194752.0000\n",
      "Epoch 119/200000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1519477248.0000 - val_loss: 484182272.0000\n",
      "Epoch 120/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1519444864.0000 - val_loss: 484169568.0000\n",
      "Epoch 121/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1519411968.0000 - val_loss: 484156640.0000\n",
      "Epoch 122/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1519378176.0000 - val_loss: 484143392.0000\n",
      "Epoch 123/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1519344000.0000 - val_loss: 484129920.0000\n",
      "Epoch 124/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1519308800.0000 - val_loss: 484116224.0000\n",
      "Epoch 125/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1519272960.0000 - val_loss: 484102208.0000\n",
      "Epoch 126/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1519236608.0000 - val_loss: 484087936.0000\n",
      "Epoch 127/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1519199488.0000 - val_loss: 484073440.0000\n",
      "Epoch 128/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1519161600.0000 - val_loss: 484058656.0000\n",
      "Epoch 129/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1519123072.0000 - val_loss: 484043552.0000\n",
      "Epoch 130/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1519083776.0000 - val_loss: 484028160.0000\n",
      "Epoch 131/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1519043584.0000 - val_loss: 484012480.0000\n",
      "Epoch 132/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1519002624.0000 - val_loss: 483996640.0000\n",
      "Epoch 133/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1518961152.0000 - val_loss: 483980416.0000\n",
      "Epoch 134/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1518918400.0000 - val_loss: 483963904.0000\n",
      "Epoch 135/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1518875008.0000 - val_loss: 483947136.0000\n",
      "Epoch 136/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1518830976.0000 - val_loss: 483929984.0000\n",
      "Epoch 137/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1518785792.0000 - val_loss: 483912512.0000\n",
      "Epoch 138/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1518739840.0000 - val_loss: 483894720.0000\n",
      "Epoch 139/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1518692992.0000 - val_loss: 483876672.0000\n",
      "Epoch 140/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1518645248.0000 - val_loss: 483858368.0000\n",
      "Epoch 141/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1518596864.0000 - val_loss: 483839648.0000\n",
      "Epoch 142/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1518547456.0000 - val_loss: 483820544.0000\n",
      "Epoch 143/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1518497152.0000 - val_loss: 483801024.0000\n",
      "Epoch 144/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1518445952.0000 - val_loss: 483781280.0000\n",
      "Epoch 145/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1518393856.0000 - val_loss: 483761056.0000\n",
      "Epoch 146/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1518340864.0000 - val_loss: 483740576.0000\n",
      "Epoch 147/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1518286976.0000 - val_loss: 483719744.0000\n",
      "Epoch 148/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1518232064.0000 - val_loss: 483698560.0000\n",
      "Epoch 149/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1518176256.0000 - val_loss: 483676960.0000\n",
      "Epoch 150/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1518119552.0000 - val_loss: 483654944.0000\n",
      "Epoch 151/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1518061568.0000 - val_loss: 483632608.0000\n",
      "Epoch 152/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1518002944.0000 - val_loss: 483609888.0000\n",
      "Epoch 153/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1517943040.0000 - val_loss: 483586816.0000\n",
      "Epoch 154/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1517882368.0000 - val_loss: 483563296.0000\n",
      "Epoch 155/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1517820416.0000 - val_loss: 483539392.0000\n",
      "Epoch 156/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1517757696.0000 - val_loss: 483515072.0000\n",
      "Epoch 157/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1517693568.0000 - val_loss: 483490368.0000\n",
      "Epoch 158/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1517628032.0000 - val_loss: 483465280.0000\n",
      "Epoch 159/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1517561600.0000 - val_loss: 483439808.0000\n",
      "Epoch 160/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1517494016.0000 - val_loss: 483413856.0000\n",
      "Epoch 161/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1517425408.0000 - val_loss: 483387520.0000\n",
      "Epoch 162/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1517355392.0000 - val_loss: 483360768.0000\n",
      "Epoch 163/200000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1517284608.0000 - val_loss: 483333696.0000\n",
      "Epoch 164/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1517212160.0000 - val_loss: 483306048.0000\n",
      "Epoch 165/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1517138432.0000 - val_loss: 483278048.0000\n",
      "Epoch 166/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1517063424.0000 - val_loss: 483249504.0000\n",
      "Epoch 167/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1516987264.0000 - val_loss: 483220544.0000\n",
      "Epoch 168/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1516909696.0000 - val_loss: 483191136.0000\n",
      "Epoch 169/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1516830848.0000 - val_loss: 483161248.0000\n",
      "Epoch 170/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1516750848.0000 - val_loss: 483130784.0000\n",
      "Epoch 171/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1516669440.0000 - val_loss: 483099936.0000\n",
      "Epoch 172/200000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1516586880.0000 - val_loss: 483068512.0000\n",
      "Epoch 173/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1516502528.0000 - val_loss: 483036640.0000\n",
      "Epoch 174/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1516416896.0000 - val_loss: 483004288.0000\n",
      "Epoch 175/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1516329984.0000 - val_loss: 482971424.0000\n",
      "Epoch 176/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1516241536.0000 - val_loss: 482938112.0000\n",
      "Epoch 177/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1516151936.0000 - val_loss: 482904224.0000\n",
      "Epoch 178/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1516061056.0000 - val_loss: 482869920.0000\n",
      "Epoch 179/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1515968768.0000 - val_loss: 482834752.0000\n",
      "Epoch 180/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1515875200.0000 - val_loss: 482798944.0000\n",
      "Epoch 181/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1515780224.0000 - val_loss: 482762688.0000\n",
      "Epoch 182/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1515683712.0000 - val_loss: 482725888.0000\n",
      "Epoch 183/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1515585920.0000 - val_loss: 482688608.0000\n",
      "Epoch 184/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1515486720.0000 - val_loss: 482650784.0000\n",
      "Epoch 185/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1515386112.0000 - val_loss: 482612480.0000\n",
      "Epoch 186/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1515283968.0000 - val_loss: 482573568.0000\n",
      "Epoch 187/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1515180672.0000 - val_loss: 482534176.0000\n",
      "Epoch 188/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1515075584.0000 - val_loss: 482494208.0000\n",
      "Epoch 189/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1514969472.0000 - val_loss: 482453824.0000\n",
      "Epoch 190/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1514861696.0000 - val_loss: 482412768.0000\n",
      "Epoch 191/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1514752512.0000 - val_loss: 482371232.0000\n",
      "Epoch 192/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1514641792.0000 - val_loss: 482329120.0000\n",
      "Epoch 193/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1514529536.0000 - val_loss: 482286496.0000\n",
      "Epoch 194/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1514415872.0000 - val_loss: 482243200.0000\n",
      "Epoch 195/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1514300800.0000 - val_loss: 482199328.0000\n",
      "Epoch 196/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1514184192.0000 - val_loss: 482154912.0000\n",
      "Epoch 197/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1514065920.0000 - val_loss: 482109984.0000\n",
      "Epoch 198/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1513946496.0000 - val_loss: 482064448.0000\n",
      "Epoch 199/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1513825152.0000 - val_loss: 482018336.0000\n",
      "Epoch 200/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1513702400.0000 - val_loss: 481971680.0000\n",
      "Epoch 201/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1513578112.0000 - val_loss: 481924384.0000\n",
      "Epoch 202/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1513452288.0000 - val_loss: 481876640.0000\n",
      "Epoch 203/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1513325056.0000 - val_loss: 481828288.0000\n",
      "Epoch 204/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1513196032.0000 - val_loss: 481779136.0000\n",
      "Epoch 205/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1513065344.0000 - val_loss: 481729504.0000\n",
      "Epoch 206/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1512933504.0000 - val_loss: 481679264.0000\n",
      "Epoch 207/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1512799744.0000 - val_loss: 481628352.0000\n",
      "Epoch 208/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1512664448.0000 - val_loss: 481576864.0000\n",
      "Epoch 209/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1512527744.0000 - val_loss: 481524768.0000\n",
      "Epoch 210/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1512388864.0000 - val_loss: 481472064.0000\n",
      "Epoch 211/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1512248832.0000 - val_loss: 481418656.0000\n",
      "Epoch 212/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1512106880.0000 - val_loss: 481364768.0000\n",
      "Epoch 213/200000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1511963264.0000 - val_loss: 481310144.0000\n",
      "Epoch 214/200000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1511818496.0000 - val_loss: 481254976.0000\n",
      "Epoch 215/200000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1511671552.0000 - val_loss: 481199136.0000\n",
      "Epoch 216/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1511523072.0000 - val_loss: 481142688.0000\n",
      "Epoch 217/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1511372672.0000 - val_loss: 481085536.0000\n",
      "Epoch 218/200000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1511220608.0000 - val_loss: 481027776.0000\n",
      "Epoch 219/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1511066880.0000 - val_loss: 480969344.0000\n",
      "Epoch 220/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1510911360.0000 - val_loss: 480910304.0000\n",
      "Epoch 221/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1510754304.0000 - val_loss: 480850592.0000\n",
      "Epoch 222/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1510595456.0000 - val_loss: 480790272.0000\n",
      "Epoch 223/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1510434688.0000 - val_loss: 480729216.0000\n",
      "Epoch 224/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1510272256.0000 - val_loss: 480667584.0000\n",
      "Epoch 225/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1510108160.0000 - val_loss: 480605312.0000\n",
      "Epoch 226/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1509942272.0000 - val_loss: 480542336.0000\n",
      "Epoch 227/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1509774464.0000 - val_loss: 480478688.0000\n",
      "Epoch 228/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1509604992.0000 - val_loss: 480414400.0000\n",
      "Epoch 229/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1509433728.0000 - val_loss: 480349472.0000\n",
      "Epoch 230/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1509260672.0000 - val_loss: 480283904.0000\n",
      "Epoch 231/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1509085568.0000 - val_loss: 480217536.0000\n",
      "Epoch 232/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1508909184.0000 - val_loss: 480150528.0000\n",
      "Epoch 233/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1508730496.0000 - val_loss: 480082848.0000\n",
      "Epoch 234/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1508550016.0000 - val_loss: 480014432.0000\n",
      "Epoch 235/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1508367872.0000 - val_loss: 479945344.0000\n",
      "Epoch 236/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1508183936.0000 - val_loss: 479875488.0000\n",
      "Epoch 237/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1507998080.0000 - val_loss: 479805024.0000\n",
      "Epoch 238/200000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1507810176.0000 - val_loss: 479733856.0000\n",
      "Epoch 239/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1507620096.0000 - val_loss: 479661888.0000\n",
      "Epoch 240/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1507428480.0000 - val_loss: 479589312.0000\n",
      "Epoch 241/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1507234688.0000 - val_loss: 479515904.0000\n",
      "Epoch 242/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1507039232.0000 - val_loss: 479441920.0000\n",
      "Epoch 243/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1506841600.0000 - val_loss: 479367104.0000\n",
      "Epoch 244/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1506642176.0000 - val_loss: 479291616.0000\n",
      "Epoch 245/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1506440832.0000 - val_loss: 479215456.0000\n",
      "Epoch 246/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1506237312.0000 - val_loss: 479138496.0000\n",
      "Epoch 247/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1506032128.0000 - val_loss: 479060768.0000\n",
      "Epoch 248/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1505824896.0000 - val_loss: 478982368.0000\n",
      "Epoch 249/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1505615616.0000 - val_loss: 478903264.0000\n",
      "Epoch 250/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1505404288.0000 - val_loss: 478823360.0000\n",
      "Epoch 251/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1505191040.0000 - val_loss: 478742784.0000\n",
      "Epoch 252/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1504975616.0000 - val_loss: 478661280.0000\n",
      "Epoch 253/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1504758144.0000 - val_loss: 478579168.0000\n",
      "Epoch 254/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1504538368.0000 - val_loss: 478496224.0000\n",
      "Epoch 255/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1504317056.0000 - val_loss: 478412544.0000\n",
      "Epoch 256/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1504092928.0000 - val_loss: 478328032.0000\n",
      "Epoch 257/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1503866880.0000 - val_loss: 478242752.0000\n",
      "Epoch 258/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1503638528.0000 - val_loss: 478156704.0000\n",
      "Epoch 259/200000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1503407872.0000 - val_loss: 478069920.0000\n",
      "Epoch 260/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1503175168.0000 - val_loss: 477982304.0000\n",
      "Epoch 261/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1502940032.0000 - val_loss: 477893984.0000\n",
      "Epoch 262/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1502702720.0000 - val_loss: 477804864.0000\n",
      "Epoch 263/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1502462976.0000 - val_loss: 477714912.0000\n",
      "Epoch 264/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1502221056.0000 - val_loss: 477624128.0000\n",
      "Epoch 265/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1501976832.0000 - val_loss: 477532640.0000\n",
      "Epoch 266/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1501730432.0000 - val_loss: 477440320.0000\n",
      "Epoch 267/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1501481856.0000 - val_loss: 477347168.0000\n",
      "Epoch 268/200000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1501231232.0000 - val_loss: 477253312.0000\n",
      "Epoch 269/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1500978048.0000 - val_loss: 477158528.0000\n",
      "Epoch 270/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1500722816.0000 - val_loss: 477062912.0000\n",
      "Epoch 271/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1500464896.0000 - val_loss: 476966560.0000\n",
      "Epoch 272/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1500204672.0000 - val_loss: 476869312.0000\n",
      "Epoch 273/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1499941760.0000 - val_loss: 476771392.0000\n",
      "Epoch 274/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1499676800.0000 - val_loss: 476672448.0000\n",
      "Epoch 275/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1499409408.0000 - val_loss: 476572800.0000\n",
      "Epoch 276/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1499139584.0000 - val_loss: 476472256.0000\n",
      "Epoch 277/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1498867200.0000 - val_loss: 476370816.0000\n",
      "Epoch 278/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1498592512.0000 - val_loss: 476268544.0000\n",
      "Epoch 279/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1498314624.0000 - val_loss: 476165440.0000\n",
      "Epoch 280/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1498033536.0000 - val_loss: 476061568.0000\n",
      "Epoch 281/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1497750016.0000 - val_loss: 475956704.0000\n",
      "Epoch 282/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1497463808.0000 - val_loss: 475850784.0000\n",
      "Epoch 283/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1497175040.0000 - val_loss: 475743552.0000\n",
      "Epoch 284/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1496883968.0000 - val_loss: 475635456.0000\n",
      "Epoch 285/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1496590080.0000 - val_loss: 475526496.0000\n",
      "Epoch 286/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1496294272.0000 - val_loss: 475416672.0000\n",
      "Epoch 287/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1495995648.0000 - val_loss: 475305888.0000\n",
      "Epoch 288/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1495694720.0000 - val_loss: 475194272.0000\n",
      "Epoch 289/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1495391360.0000 - val_loss: 475081760.0000\n",
      "Epoch 290/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1495085568.0000 - val_loss: 474968320.0000\n",
      "Epoch 291/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1494777472.0000 - val_loss: 474853952.0000\n",
      "Epoch 292/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1494466560.0000 - val_loss: 474738720.0000\n",
      "Epoch 293/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1494153088.0000 - val_loss: 474622592.0000\n",
      "Epoch 294/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1493837184.0000 - val_loss: 474505504.0000\n",
      "Epoch 295/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1493518592.0000 - val_loss: 474387584.0000\n",
      "Epoch 296/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1493197440.0000 - val_loss: 474268736.0000\n",
      "Epoch 297/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1492873344.0000 - val_loss: 474148992.0000\n",
      "Epoch 298/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1492546688.0000 - val_loss: 474028288.0000\n",
      "Epoch 299/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1492217344.0000 - val_loss: 473906752.0000\n",
      "Epoch 300/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1491885568.0000 - val_loss: 473784224.0000\n",
      "Epoch 301/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1491550976.0000 - val_loss: 473660800.0000\n",
      "Epoch 302/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1491213824.0000 - val_loss: 473536448.0000\n",
      "Epoch 303/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1490874240.0000 - val_loss: 473410400.0000\n",
      "Epoch 304/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1490532224.0000 - val_loss: 473282912.0000\n",
      "Epoch 305/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1490187520.0000 - val_loss: 473154496.0000\n",
      "Epoch 306/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1489840128.0000 - val_loss: 473025184.0000\n",
      "Epoch 307/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1489490432.0000 - val_loss: 472894816.0000\n",
      "Epoch 308/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1489137920.0000 - val_loss: 472763616.0000\n",
      "Epoch 309/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1488782848.0000 - val_loss: 472631456.0000\n",
      "Epoch 310/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1488425344.0000 - val_loss: 472498304.0000\n",
      "Epoch 311/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1488064768.0000 - val_loss: 472364192.0000\n",
      "Epoch 312/200000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1487701888.0000 - val_loss: 472229152.0000\n",
      "Epoch 313/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1487335936.0000 - val_loss: 472093152.0000\n",
      "Epoch 314/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1486967808.0000 - val_loss: 471956288.0000\n",
      "Epoch 315/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1486596992.0000 - val_loss: 471818400.0000\n",
      "Epoch 316/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1486223488.0000 - val_loss: 471679552.0000\n",
      "Epoch 317/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1485847552.0000 - val_loss: 471539808.0000\n",
      "Epoch 318/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1485468800.0000 - val_loss: 471399072.0000\n",
      "Epoch 319/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1485087232.0000 - val_loss: 471257408.0000\n",
      "Epoch 320/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1484702976.0000 - val_loss: 471114720.0000\n",
      "Epoch 321/200000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1484315904.0000 - val_loss: 470971040.0000\n",
      "Epoch 322/200000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1483926528.0000 - val_loss: 470826432.0000\n",
      "Epoch 323/200000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1483534080.0000 - val_loss: 470680864.0000\n",
      "Epoch 324/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1483139200.0000 - val_loss: 470534304.0000\n",
      "Epoch 325/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1482741376.0000 - val_loss: 470386816.0000\n",
      "Epoch 326/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1482341376.0000 - val_loss: 470238240.0000\n",
      "Epoch 327/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1481938304.0000 - val_loss: 470088736.0000\n",
      "Epoch 328/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1481532544.0000 - val_loss: 469938336.0000\n",
      "Epoch 329/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1481124352.0000 - val_loss: 469786912.0000\n",
      "Epoch 330/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1480713344.0000 - val_loss: 469634464.0000\n",
      "Epoch 331/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1480299264.0000 - val_loss: 469481088.0000\n",
      "Epoch 332/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1479882880.0000 - val_loss: 469326688.0000\n",
      "Epoch 333/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1479463552.0000 - val_loss: 469171296.0000\n",
      "Epoch 334/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1479041664.0000 - val_loss: 469014944.0000\n",
      "Epoch 335/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1478616832.0000 - val_loss: 468857600.0000\n",
      "Epoch 336/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1478189568.0000 - val_loss: 468699264.0000\n",
      "Epoch 337/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1477759360.0000 - val_loss: 468539872.0000\n",
      "Epoch 338/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1477326592.0000 - val_loss: 468379584.0000\n",
      "Epoch 339/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1476891264.0000 - val_loss: 468218208.0000\n",
      "Epoch 340/200000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1476452864.0000 - val_loss: 468055872.0000\n",
      "Epoch 341/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1476011648.0000 - val_loss: 467892544.0000\n",
      "Epoch 342/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1475568000.0000 - val_loss: 467728224.0000\n",
      "Epoch 343/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1475121408.0000 - val_loss: 467562848.0000\n",
      "Epoch 344/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1474672128.0000 - val_loss: 467396544.0000\n",
      "Epoch 345/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1474220160.0000 - val_loss: 467229152.0000\n",
      "Epoch 346/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1473765248.0000 - val_loss: 467060864.0000\n",
      "Epoch 347/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1473307520.0000 - val_loss: 466891520.0000\n",
      "Epoch 348/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1472847232.0000 - val_loss: 466721120.0000\n",
      "Epoch 349/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1472383872.0000 - val_loss: 466549728.0000\n",
      "Epoch 350/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1471917824.0000 - val_loss: 466377376.0000\n",
      "Epoch 351/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1471449088.0000 - val_loss: 466203904.0000\n",
      "Epoch 352/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1470977280.0000 - val_loss: 466029504.0000\n",
      "Epoch 353/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1470503040.0000 - val_loss: 465854080.0000\n",
      "Epoch 354/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1470025728.0000 - val_loss: 465677600.0000\n",
      "Epoch 355/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1469545728.0000 - val_loss: 465500160.0000\n",
      "Epoch 356/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1469062784.0000 - val_loss: 465321696.0000\n",
      "Epoch 357/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1468577280.0000 - val_loss: 465142112.0000\n",
      "Epoch 358/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1468088320.0000 - val_loss: 464961632.0000\n",
      "Epoch 359/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1467596544.0000 - val_loss: 464780064.0000\n",
      "Epoch 360/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1467101952.0000 - val_loss: 464597216.0000\n",
      "Epoch 361/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1466604544.0000 - val_loss: 464413312.0000\n",
      "Epoch 362/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1466104064.0000 - val_loss: 464228384.0000\n",
      "Epoch 363/200000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1465601024.0000 - val_loss: 464042464.0000\n",
      "Epoch 364/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1465094912.0000 - val_loss: 463855456.0000\n",
      "Epoch 365/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1464585984.0000 - val_loss: 463667424.0000\n",
      "Epoch 366/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1464073984.0000 - val_loss: 463478336.0000\n",
      "Epoch 367/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1463559296.0000 - val_loss: 463288256.0000\n",
      "Epoch 368/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1463041536.0000 - val_loss: 463097056.0000\n",
      "Epoch 369/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1462521088.0000 - val_loss: 462904800.0000\n",
      "Epoch 370/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1461997440.0000 - val_loss: 462711552.0000\n",
      "Epoch 371/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1461471360.0000 - val_loss: 462517280.0000\n",
      "Epoch 372/200000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1460942080.0000 - val_loss: 462321920.0000\n",
      "Epoch 373/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1460409856.0000 - val_loss: 462125408.0000\n",
      "Epoch 374/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1459874816.0000 - val_loss: 461927968.0000\n",
      "Epoch 375/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1459336832.0000 - val_loss: 461729344.0000\n",
      "Epoch 376/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1458795904.0000 - val_loss: 461529760.0000\n",
      "Epoch 377/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1458252160.0000 - val_loss: 461328992.0000\n",
      "Epoch 378/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1457705472.0000 - val_loss: 461127232.0000\n",
      "Epoch 379/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1457155584.0000 - val_loss: 460924448.0000\n",
      "Epoch 380/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1456603008.0000 - val_loss: 460720544.0000\n",
      "Epoch 381/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1456047360.0000 - val_loss: 460515616.0000\n",
      "Epoch 382/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1455488896.0000 - val_loss: 460309632.0000\n",
      "Epoch 383/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1454927104.0000 - val_loss: 460102560.0000\n",
      "Epoch 384/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1454362752.0000 - val_loss: 459894432.0000\n",
      "Epoch 385/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1453795456.0000 - val_loss: 459685216.0000\n",
      "Epoch 386/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1453225216.0000 - val_loss: 459474976.0000\n",
      "Epoch 387/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1452651392.0000 - val_loss: 459263744.0000\n",
      "Epoch 388/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1452074752.0000 - val_loss: 459051328.0000\n",
      "Epoch 389/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1451494912.0000 - val_loss: 458837792.0000\n",
      "Epoch 390/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1450911488.0000 - val_loss: 458623296.0000\n",
      "Epoch 391/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1450324480.0000 - val_loss: 458407552.0000\n",
      "Epoch 392/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1449734272.0000 - val_loss: 458190752.0000\n",
      "Epoch 393/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1449139456.0000 - val_loss: 457972896.0000\n",
      "Epoch 394/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1448540544.0000 - val_loss: 457753920.0000\n",
      "Epoch 395/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1447938176.0000 - val_loss: 457533824.0000\n",
      "Epoch 396/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1447331584.0000 - val_loss: 457312608.0000\n",
      "Epoch 397/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1446721408.0000 - val_loss: 457090336.0000\n",
      "Epoch 398/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1446107520.0000 - val_loss: 456866976.0000\n",
      "Epoch 399/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1445490048.0000 - val_loss: 456642496.0000\n",
      "Epoch 400/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1444869376.0000 - val_loss: 456416896.0000\n",
      "Epoch 401/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1444245248.0000 - val_loss: 456190240.0000\n",
      "Epoch 402/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1443617920.0000 - val_loss: 455962528.0000\n",
      "Epoch 403/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1442987648.0000 - val_loss: 455733632.0000\n",
      "Epoch 404/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1442354048.0000 - val_loss: 455503648.0000\n",
      "Epoch 405/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1441716608.0000 - val_loss: 455272288.0000\n",
      "Epoch 406/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1441075584.0000 - val_loss: 455039712.0000\n",
      "Epoch 407/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1440431232.0000 - val_loss: 454806144.0000\n",
      "Epoch 408/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1439783552.0000 - val_loss: 454571296.0000\n",
      "Epoch 409/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1439133184.0000 - val_loss: 454335488.0000\n",
      "Epoch 410/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1438479616.0000 - val_loss: 454098560.0000\n",
      "Epoch 411/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1437822592.0000 - val_loss: 453860480.0000\n",
      "Epoch 412/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1437162752.0000 - val_loss: 453621344.0000\n",
      "Epoch 413/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1436499584.0000 - val_loss: 453381056.0000\n",
      "Epoch 414/200000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1435833472.0000 - val_loss: 453139680.0000\n",
      "Epoch 415/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1435164160.0000 - val_loss: 452897248.0000\n",
      "Epoch 416/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1434491904.0000 - val_loss: 452653728.0000\n",
      "Epoch 417/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1433816320.0000 - val_loss: 452409024.0000\n",
      "Epoch 418/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1433137920.0000 - val_loss: 452163200.0000\n",
      "Epoch 419/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1432456064.0000 - val_loss: 451916320.0000\n",
      "Epoch 420/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1431771520.0000 - val_loss: 451668320.0000\n",
      "Epoch 421/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1431083648.0000 - val_loss: 451419200.0000\n",
      "Epoch 422/200000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1430392832.0000 - val_loss: 451169056.0000\n",
      "Epoch 423/200000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1429698816.0000 - val_loss: 450917696.0000\n",
      "Epoch 424/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1429001600.0000 - val_loss: 450665248.0000\n",
      "Epoch 425/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1428301568.0000 - val_loss: 450410272.0000\n",
      "Epoch 426/200000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1427598336.0000 - val_loss: 450152992.0000\n",
      "Epoch 427/200000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1426892032.0000 - val_loss: 449894560.0000\n",
      "Epoch 428/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1426182528.0000 - val_loss: 449635040.0000\n",
      "Epoch 429/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1425469440.0000 - val_loss: 449374368.0000\n",
      "Epoch 430/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1424753280.0000 - val_loss: 449112544.0000\n",
      "Epoch 431/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1424034176.0000 - val_loss: 448849664.0000\n",
      "Epoch 432/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1423311872.0000 - val_loss: 448585664.0000\n",
      "Epoch 433/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1422586368.0000 - val_loss: 448320544.0000\n",
      "Epoch 434/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1421857792.0000 - val_loss: 448054240.0000\n",
      "Epoch 435/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1421125632.0000 - val_loss: 447786784.0000\n",
      "Epoch 436/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1420390144.0000 - val_loss: 447518272.0000\n",
      "Epoch 437/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1419651584.0000 - val_loss: 447248576.0000\n",
      "Epoch 438/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1418909696.0000 - val_loss: 446977728.0000\n",
      "Epoch 439/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1418164736.0000 - val_loss: 446705792.0000\n",
      "Epoch 440/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1417416448.0000 - val_loss: 446432672.0000\n",
      "Epoch 441/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1416664448.0000 - val_loss: 446158464.0000\n",
      "Epoch 442/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1415908608.0000 - val_loss: 445881248.0000\n",
      "Epoch 443/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1415148544.0000 - val_loss: 445602240.0000\n",
      "Epoch 444/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1414380160.0000 - val_loss: 445321344.0000\n",
      "Epoch 445/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1413606656.0000 - val_loss: 445038432.0000\n",
      "Epoch 446/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1412827648.0000 - val_loss: 444753920.0000\n",
      "Epoch 447/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1412044160.0000 - val_loss: 444467840.0000\n",
      "Epoch 448/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1411256576.0000 - val_loss: 444180288.0000\n",
      "Epoch 449/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1410465024.0000 - val_loss: 443891360.0000\n",
      "Epoch 450/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1409669120.0000 - val_loss: 443600992.0000\n",
      "Epoch 451/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1408869632.0000 - val_loss: 443309312.0000\n",
      "Epoch 452/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1408066176.0000 - val_loss: 443016224.0000\n",
      "Epoch 453/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1407258880.0000 - val_loss: 442721760.0000\n",
      "Epoch 454/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1406447616.0000 - val_loss: 442426048.0000\n",
      "Epoch 455/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1405633024.0000 - val_loss: 442129024.0000\n",
      "Epoch 456/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1404814592.0000 - val_loss: 441830528.0000\n",
      "Epoch 457/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1403992448.0000 - val_loss: 441530816.0000\n",
      "Epoch 458/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1403166848.0000 - val_loss: 441229888.0000\n",
      "Epoch 459/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1402337280.0000 - val_loss: 440927584.0000\n",
      "Epoch 460/200000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1401504256.0000 - val_loss: 440624000.0000\n",
      "Epoch 461/200000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1400667776.0000 - val_loss: 440319168.0000\n",
      "Epoch 462/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1399827456.0000 - val_loss: 440012992.0000\n",
      "Epoch 463/200000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1398983680.0000 - val_loss: 439705632.0000\n",
      "Epoch 464/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1398136192.0000 - val_loss: 439396960.0000\n",
      "Epoch 465/200000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1397285504.0000 - val_loss: 439086976.0000\n",
      "Epoch 466/200000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1396430848.0000 - val_loss: 438775680.0000\n",
      "Epoch 467/200000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1395572608.0000 - val_loss: 438462752.0000\n",
      "Epoch 468/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1394710912.0000 - val_loss: 438148512.0000\n",
      "Epoch 469/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1393845376.0000 - val_loss: 437833056.0000\n",
      "Epoch 470/200000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1392976512.0000 - val_loss: 437516320.0000\n",
      "Epoch 471/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1392103936.0000 - val_loss: 437198368.0000\n",
      "Epoch 472/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1391227904.0000 - val_loss: 436879104.0000\n",
      "Epoch 473/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1390348288.0000 - val_loss: 436558592.0000\n",
      "Epoch 474/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1389465344.0000 - val_loss: 436236832.0000\n",
      "Epoch 475/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1388578432.0000 - val_loss: 435913824.0000\n",
      "Epoch 476/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1387688448.0000 - val_loss: 435589664.0000\n",
      "Epoch 477/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1386794880.0000 - val_loss: 435264096.0000\n",
      "Epoch 478/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1385897344.0000 - val_loss: 434937408.0000\n",
      "Epoch 479/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1384996736.0000 - val_loss: 434609440.0000\n",
      "Epoch 480/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1384092544.0000 - val_loss: 434280224.0000\n",
      "Epoch 481/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1383184768.0000 - val_loss: 433949728.0000\n",
      "Epoch 482/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1382273536.0000 - val_loss: 433618080.0000\n",
      "Epoch 483/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1381358848.0000 - val_loss: 433285088.0000\n",
      "Epoch 484/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1380440704.0000 - val_loss: 432950912.0000\n",
      "Epoch 485/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1379518976.0000 - val_loss: 432615552.0000\n",
      "Epoch 486/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1378593792.0000 - val_loss: 432278848.0000\n",
      "Epoch 487/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1377665024.0000 - val_loss: 431940928.0000\n",
      "Epoch 488/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1376732928.0000 - val_loss: 431601856.0000\n",
      "Epoch 489/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1375797376.0000 - val_loss: 431261536.0000\n",
      "Epoch 490/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1374858112.0000 - val_loss: 430919968.0000\n",
      "Epoch 491/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1373915520.0000 - val_loss: 430577184.0000\n",
      "Epoch 492/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1372969728.0000 - val_loss: 430233216.0000\n",
      "Epoch 493/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1372019968.0000 - val_loss: 429887936.0000\n",
      "Epoch 494/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1371067136.0000 - val_loss: 429541568.0000\n",
      "Epoch 495/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1370110464.0000 - val_loss: 429193888.0000\n",
      "Epoch 496/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1369150592.0000 - val_loss: 428845056.0000\n",
      "Epoch 497/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1368187392.0000 - val_loss: 428494944.0000\n",
      "Epoch 498/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1367220608.0000 - val_loss: 428143648.0000\n",
      "Epoch 499/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1366250368.0000 - val_loss: 427791168.0000\n",
      "Epoch 500/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1365276672.0000 - val_loss: 427437472.0000\n",
      "Epoch 501/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1364299776.0000 - val_loss: 427082592.0000\n",
      "Epoch 502/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1363319168.0000 - val_loss: 426726464.0000\n",
      "Epoch 503/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1362334976.0000 - val_loss: 426369120.0000\n",
      "Epoch 504/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1361347584.0000 - val_loss: 426010624.0000\n",
      "Epoch 505/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1360356864.0000 - val_loss: 425650912.0000\n",
      "Epoch 506/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1359362560.0000 - val_loss: 425290016.0000\n",
      "Epoch 507/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1358365056.0000 - val_loss: 424927936.0000\n",
      "Epoch 508/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1357364224.0000 - val_loss: 424564640.0000\n",
      "Epoch 509/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1356359424.0000 - val_loss: 424200128.0000\n",
      "Epoch 510/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1355351680.0000 - val_loss: 423834464.0000\n",
      "Epoch 511/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1354340480.0000 - val_loss: 423467616.0000\n",
      "Epoch 512/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1353325696.0000 - val_loss: 423099584.0000\n",
      "Epoch 513/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1352307840.0000 - val_loss: 422730368.0000\n",
      "Epoch 514/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1351286400.0000 - val_loss: 422359936.0000\n",
      "Epoch 515/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1350261504.0000 - val_loss: 421988320.0000\n",
      "Epoch 516/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1349233408.0000 - val_loss: 421615552.0000\n",
      "Epoch 517/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1348201600.0000 - val_loss: 421241600.0000\n",
      "Epoch 518/200000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1347166720.0000 - val_loss: 420866464.0000\n",
      "Epoch 519/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1346128256.0000 - val_loss: 420490240.0000\n",
      "Epoch 520/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1345086720.0000 - val_loss: 420112736.0000\n",
      "Epoch 521/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1344041472.0000 - val_loss: 419734144.0000\n",
      "Epoch 522/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1342993152.0000 - val_loss: 419354336.0000\n",
      "Epoch 523/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1341941248.0000 - val_loss: 418973280.0000\n",
      "Epoch 524/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1340886016.0000 - val_loss: 418591072.0000\n",
      "Epoch 525/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1339827584.0000 - val_loss: 418207648.0000\n",
      "Epoch 526/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1338765568.0000 - val_loss: 417823136.0000\n",
      "Epoch 527/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1337700224.0000 - val_loss: 417437440.0000\n",
      "Epoch 528/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1336631936.0000 - val_loss: 417050624.0000\n",
      "Epoch 529/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1335560064.0000 - val_loss: 416662592.0000\n",
      "Epoch 530/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1334484608.0000 - val_loss: 416273440.0000\n",
      "Epoch 531/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1333406336.0000 - val_loss: 415883168.0000\n",
      "Epoch 532/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1332324352.0000 - val_loss: 415491712.0000\n",
      "Epoch 533/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1331239168.0000 - val_loss: 415099040.0000\n",
      "Epoch 534/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1330150656.0000 - val_loss: 414705312.0000\n",
      "Epoch 535/200000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1329058688.0000 - val_loss: 414310400.0000\n",
      "Epoch 536/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1327963648.0000 - val_loss: 413914336.0000\n",
      "Epoch 537/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1326865152.0000 - val_loss: 413517152.0000\n",
      "Epoch 538/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1325763584.0000 - val_loss: 413118880.0000\n",
      "Epoch 539/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1324658688.0000 - val_loss: 412719392.0000\n",
      "Epoch 540/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1323550336.0000 - val_loss: 412318816.0000\n",
      "Epoch 541/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1322438784.0000 - val_loss: 411917120.0000\n",
      "Epoch 542/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1321324032.0000 - val_loss: 411514240.0000\n",
      "Epoch 543/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1320206080.0000 - val_loss: 411110304.0000\n",
      "Epoch 544/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1319084672.0000 - val_loss: 410705184.0000\n",
      "Epoch 545/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1317960192.0000 - val_loss: 410298976.0000\n",
      "Epoch 546/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1316832512.0000 - val_loss: 409891616.0000\n",
      "Epoch 547/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1315701248.0000 - val_loss: 409483200.0000\n",
      "Epoch 548/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1314567040.0000 - val_loss: 409073600.0000\n",
      "Epoch 549/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1313429632.0000 - val_loss: 408662880.0000\n",
      "Epoch 550/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1312288640.0000 - val_loss: 408251104.0000\n",
      "Epoch 551/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1311144960.0000 - val_loss: 407838144.0000\n",
      "Epoch 552/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1309997568.0000 - val_loss: 407424128.0000\n",
      "Epoch 553/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1308847232.0000 - val_loss: 407009024.0000\n",
      "Epoch 554/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1307693696.0000 - val_loss: 406592736.0000\n",
      "Epoch 555/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1306536960.0000 - val_loss: 406175424.0000\n",
      "Epoch 556/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1305376896.0000 - val_loss: 405756992.0000\n",
      "Epoch 557/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1304213632.0000 - val_loss: 405337504.0000\n",
      "Epoch 558/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1303047296.0000 - val_loss: 404916960.0000\n",
      "Epoch 559/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1301877632.0000 - val_loss: 404495264.0000\n",
      "Epoch 560/200000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1300705152.0000 - val_loss: 404072480.0000\n",
      "Epoch 561/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1299529216.0000 - val_loss: 403648672.0000\n",
      "Epoch 562/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1298350208.0000 - val_loss: 403223712.0000\n",
      "Epoch 563/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1297168000.0000 - val_loss: 402797760.0000\n",
      "Epoch 564/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1295982464.0000 - val_loss: 402370656.0000\n",
      "Epoch 565/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1294794112.0000 - val_loss: 401942528.0000\n",
      "Epoch 566/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1293602688.0000 - val_loss: 401513312.0000\n",
      "Epoch 567/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1292407808.0000 - val_loss: 401083072.0000\n",
      "Epoch 568/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1291209984.0000 - val_loss: 400651744.0000\n",
      "Epoch 569/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1290008960.0000 - val_loss: 400219328.0000\n",
      "Epoch 570/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1288804992.0000 - val_loss: 399785856.0000\n",
      "Epoch 571/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1287597824.0000 - val_loss: 399351392.0000\n",
      "Epoch 572/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1286387712.0000 - val_loss: 398915872.0000\n",
      "Epoch 573/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1285174528.0000 - val_loss: 398479296.0000\n",
      "Epoch 574/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1283958016.0000 - val_loss: 398041664.0000\n",
      "Epoch 575/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1282738688.0000 - val_loss: 397603040.0000\n",
      "Epoch 576/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1281516288.0000 - val_loss: 397163328.0000\n",
      "Epoch 577/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1280290688.0000 - val_loss: 396722592.0000\n",
      "Epoch 578/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1279062144.0000 - val_loss: 396280864.0000\n",
      "Epoch 579/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1277830400.0000 - val_loss: 395838112.0000\n",
      "Epoch 580/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1276595968.0000 - val_loss: 395394208.0000\n",
      "Epoch 581/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1275358336.0000 - val_loss: 394949440.0000\n",
      "Epoch 582/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1274117760.0000 - val_loss: 394503552.0000\n",
      "Epoch 583/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1272873984.0000 - val_loss: 394056768.0000\n",
      "Epoch 584/200000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1271627392.0000 - val_loss: 393608928.0000\n",
      "Epoch 585/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1270377728.0000 - val_loss: 393159968.0000\n",
      "Epoch 586/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1269125248.0000 - val_loss: 392710208.0000\n",
      "Epoch 587/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1267869568.0000 - val_loss: 392259296.0000\n",
      "Epoch 588/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1266611072.0000 - val_loss: 391807456.0000\n",
      "Epoch 589/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1265349632.0000 - val_loss: 391354592.0000\n",
      "Epoch 590/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1264084992.0000 - val_loss: 390900768.0000\n",
      "Epoch 591/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1262817664.0000 - val_loss: 390445920.0000\n",
      "Epoch 592/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1261547264.0000 - val_loss: 389990112.0000\n",
      "Epoch 593/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1260274048.0000 - val_loss: 389533344.0000\n",
      "Epoch 594/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1258997888.0000 - val_loss: 389075552.0000\n",
      "Epoch 595/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1257718656.0000 - val_loss: 388616768.0000\n",
      "Epoch 596/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1256436992.0000 - val_loss: 388157024.0000\n",
      "Epoch 597/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1255152000.0000 - val_loss: 387696288.0000\n",
      "Epoch 598/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1253864192.0000 - val_loss: 387234624.0000\n",
      "Epoch 599/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1252573440.0000 - val_loss: 386772000.0000\n",
      "Epoch 600/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1251279872.0000 - val_loss: 386308448.0000\n",
      "Epoch 601/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1249983744.0000 - val_loss: 385843872.0000\n",
      "Epoch 602/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1248684416.0000 - val_loss: 385378400.0000\n",
      "Epoch 603/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1247382272.0000 - val_loss: 384912000.0000\n",
      "Epoch 604/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1246077440.0000 - val_loss: 384444608.0000\n",
      "Epoch 605/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1244769792.0000 - val_loss: 383976320.0000\n",
      "Epoch 606/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1243459200.0000 - val_loss: 383507104.0000\n",
      "Epoch 607/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1242145920.0000 - val_loss: 383036992.0000\n",
      "Epoch 608/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1240829824.0000 - val_loss: 382565856.0000\n",
      "Epoch 609/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1239510784.0000 - val_loss: 382093856.0000\n",
      "Epoch 610/200000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1238189312.0000 - val_loss: 381620960.0000\n",
      "Epoch 611/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1236864640.0000 - val_loss: 381147136.0000\n",
      "Epoch 612/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1235537536.0000 - val_loss: 380672416.0000\n",
      "Epoch 613/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1234207488.0000 - val_loss: 380196704.0000\n",
      "Epoch 614/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1232874752.0000 - val_loss: 379720128.0000\n",
      "Epoch 615/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1231539200.0000 - val_loss: 379242752.0000\n",
      "Epoch 616/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1230201088.0000 - val_loss: 378764352.0000\n",
      "Epoch 617/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1228860288.0000 - val_loss: 378285184.0000\n",
      "Epoch 618/200000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1227516672.0000 - val_loss: 377805024.0000\n",
      "Epoch 619/200000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1226170240.0000 - val_loss: 377324000.0000\n",
      "Epoch 620/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1224821504.0000 - val_loss: 376842176.0000\n",
      "Epoch 621/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1223469824.0000 - val_loss: 376359392.0000\n",
      "Epoch 622/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1222115584.0000 - val_loss: 375875840.0000\n",
      "Epoch 623/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1220758656.0000 - val_loss: 375391264.0000\n",
      "Epoch 624/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1219398784.0000 - val_loss: 374905952.0000\n",
      "Epoch 625/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1218036736.0000 - val_loss: 374419744.0000\n",
      "Epoch 626/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1216672000.0000 - val_loss: 373932736.0000\n",
      "Epoch 627/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1215304448.0000 - val_loss: 373444800.0000\n",
      "Epoch 628/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1213934592.0000 - val_loss: 372956032.0000\n",
      "Epoch 629/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1212561664.0000 - val_loss: 372466464.0000\n",
      "Epoch 630/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1211186560.0000 - val_loss: 371976032.0000\n",
      "Epoch 631/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1209808768.0000 - val_loss: 371484800.0000\n",
      "Epoch 632/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1208428288.0000 - val_loss: 370992672.0000\n",
      "Epoch 633/200000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1207045376.0000 - val_loss: 370499744.0000\n",
      "Epoch 634/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1205660032.0000 - val_loss: 370006016.0000\n",
      "Epoch 635/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1204271872.0000 - val_loss: 369511520.0000\n",
      "Epoch 636/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1202881408.0000 - val_loss: 369016064.0000\n",
      "Epoch 637/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1201488384.0000 - val_loss: 368519968.0000\n",
      "Epoch 638/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1200092800.0000 - val_loss: 368022944.0000\n",
      "Epoch 639/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1198694784.0000 - val_loss: 367525248.0000\n",
      "Epoch 640/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1197294208.0000 - val_loss: 367026624.0000\n",
      "Epoch 641/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1195891328.0000 - val_loss: 366527296.0000\n",
      "Epoch 642/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1194485760.0000 - val_loss: 366027136.0000\n",
      "Epoch 643/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1193077888.0000 - val_loss: 365526240.0000\n",
      "Epoch 644/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1191667456.0000 - val_loss: 365024512.0000\n",
      "Epoch 645/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1190254848.0000 - val_loss: 364522048.0000\n",
      "Epoch 646/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1188839680.0000 - val_loss: 364018848.0000\n",
      "Epoch 647/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1187421952.0000 - val_loss: 363514880.0000\n",
      "Epoch 648/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1186002048.0000 - val_loss: 363010048.0000\n",
      "Epoch 649/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1184579712.0000 - val_loss: 362504512.0000\n",
      "Epoch 650/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1183155072.0000 - val_loss: 361998272.0000\n",
      "Epoch 651/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1181728000.0000 - val_loss: 361491264.0000\n",
      "Epoch 652/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1180298496.0000 - val_loss: 360983552.0000\n",
      "Epoch 653/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1178866816.0000 - val_loss: 360474976.0000\n",
      "Epoch 654/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1177432576.0000 - val_loss: 359965824.0000\n",
      "Epoch 655/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1175996288.0000 - val_loss: 359455872.0000\n",
      "Epoch 656/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1174557568.0000 - val_loss: 358945216.0000\n",
      "Epoch 657/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1173116800.0000 - val_loss: 358433888.0000\n",
      "Epoch 658/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1171673344.0000 - val_loss: 357921728.0000\n",
      "Epoch 659/200000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1170227712.0000 - val_loss: 357409024.0000\n",
      "Epoch 660/200000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1168780160.0000 - val_loss: 356895552.0000\n",
      "Epoch 661/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1167329920.0000 - val_loss: 356381408.0000\n",
      "Epoch 662/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1165877888.0000 - val_loss: 355866528.0000\n",
      "Epoch 663/200000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1164423296.0000 - val_loss: 355350944.0000\n",
      "Epoch 664/200000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1162966656.0000 - val_loss: 354834720.0000\n",
      "Epoch 665/200000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1161507840.0000 - val_loss: 354317888.0000\n",
      "Epoch 666/200000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1160046976.0000 - val_loss: 353800320.0000\n",
      "Epoch 667/200000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1158583552.0000 - val_loss: 353282016.0000\n",
      "Epoch 668/200000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1157118208.0000 - val_loss: 352763104.0000\n",
      "Epoch 669/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1155650816.0000 - val_loss: 352243584.0000\n",
      "Epoch 670/200000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1154181120.0000 - val_loss: 351723328.0000\n",
      "Epoch 671/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1152709504.0000 - val_loss: 351202496.0000\n",
      "Epoch 672/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1151235456.0000 - val_loss: 350680992.0000\n",
      "Epoch 673/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1149759488.0000 - val_loss: 350158848.0000\n",
      "Epoch 674/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1148281600.0000 - val_loss: 349636064.0000\n",
      "Epoch 675/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1146801408.0000 - val_loss: 349112704.0000\n",
      "Epoch 676/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1145319168.0000 - val_loss: 348588672.0000\n",
      "Epoch 677/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1143835008.0000 - val_loss: 348064032.0000\n",
      "Epoch 678/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1142348800.0000 - val_loss: 347538816.0000\n",
      "Epoch 679/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1140860544.0000 - val_loss: 347013056.0000\n",
      "Epoch 680/200000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1139370112.0000 - val_loss: 346486560.0000\n",
      "Epoch 681/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1137878016.0000 - val_loss: 345959488.0000\n",
      "Epoch 682/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1136383616.0000 - val_loss: 345431904.0000\n",
      "Epoch 683/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1134887424.0000 - val_loss: 344903680.0000\n",
      "Epoch 684/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1133389184.0000 - val_loss: 344374880.0000\n",
      "Epoch 685/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1131889152.0000 - val_loss: 343845568.0000\n",
      "Epoch 686/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1130387072.0000 - val_loss: 343315584.0000\n",
      "Epoch 687/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1128883072.0000 - val_loss: 342785088.0000\n",
      "Epoch 688/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1127377408.0000 - val_loss: 342254016.0000\n",
      "Epoch 689/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1125869568.0000 - val_loss: 341722368.0000\n",
      "Epoch 690/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1124359936.0000 - val_loss: 341190272.0000\n",
      "Epoch 691/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1122848640.0000 - val_loss: 340657568.0000\n",
      "Epoch 692/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1121335168.0000 - val_loss: 340124352.0000\n",
      "Epoch 693/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1119820032.0000 - val_loss: 339590528.0000\n",
      "Epoch 694/200000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1118303104.0000 - val_loss: 339056288.0000\n",
      "Epoch 695/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1116784256.0000 - val_loss: 338521408.0000\n",
      "Epoch 696/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1115263616.0000 - val_loss: 337986176.0000\n",
      "Epoch 697/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1113741312.0000 - val_loss: 337450304.0000\n",
      "Epoch 698/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1112217088.0000 - val_loss: 336913984.0000\n",
      "Epoch 699/200000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1110691328.0000 - val_loss: 336377120.0000\n",
      "Epoch 700/200000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1109163648.0000 - val_loss: 335839808.0000\n",
      "Epoch 701/200000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1107634304.0000 - val_loss: 335301952.0000\n",
      "Epoch 702/200000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1106103168.0000 - val_loss: 334763680.0000\n",
      "Epoch 703/200000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1104570368.0000 - val_loss: 334224832.0000\n",
      "Epoch 704/200000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1103036160.0000 - val_loss: 333685600.0000\n",
      "Epoch 705/200000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1101500032.0000 - val_loss: 333145888.0000\n",
      "Epoch 706/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1099962368.0000 - val_loss: 332605664.0000\n",
      "Epoch 707/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1098422784.0000 - val_loss: 332065056.0000\n",
      "Epoch 708/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1096881792.0000 - val_loss: 331523968.0000\n",
      "Epoch 709/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1095339136.0000 - val_loss: 330982432.0000\n",
      "Epoch 710/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1093794944.0000 - val_loss: 330440480.0000\n",
      "Epoch 711/200000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1092249088.0000 - val_loss: 329898048.0000\n",
      "Epoch 712/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1090701696.0000 - val_loss: 329355232.0000\n",
      "Epoch 713/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1089152768.0000 - val_loss: 328812000.0000\n",
      "Epoch 714/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1087602304.0000 - val_loss: 328268352.0000\n",
      "Epoch 715/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1086050176.0000 - val_loss: 327724320.0000\n",
      "Epoch 716/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1084496640.0000 - val_loss: 327179840.0000\n",
      "Epoch 717/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1082941696.0000 - val_loss: 326634944.0000\n",
      "Epoch 718/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1081385216.0000 - val_loss: 326089696.0000\n",
      "Epoch 719/200000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1079827200.0000 - val_loss: 325544064.0000\n",
      "Epoch 720/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1078267648.0000 - val_loss: 324998016.0000\n",
      "Epoch 721/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1076706688.0000 - val_loss: 324451552.0000\n",
      "Epoch 722/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1075144320.0000 - val_loss: 323904800.0000\n",
      "Epoch 723/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1073580672.0000 - val_loss: 323357696.0000\n",
      "Epoch 724/200000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1072015552.0000 - val_loss: 322810176.0000\n",
      "Epoch 725/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1070449024.0000 - val_loss: 322262304.0000\n",
      "Epoch 726/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1068881152.0000 - val_loss: 321714112.0000\n",
      "Epoch 727/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1067311872.0000 - val_loss: 321165568.0000\n",
      "Epoch 728/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1065741120.0000 - val_loss: 320616736.0000\n",
      "Epoch 729/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1064169280.0000 - val_loss: 320067520.0000\n",
      "Epoch 730/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1062596032.0000 - val_loss: 319517984.0000\n",
      "Epoch 731/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1061021504.0000 - val_loss: 318968160.0000\n",
      "Epoch 732/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1059445696.0000 - val_loss: 318418048.0000\n",
      "Epoch 733/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1057868608.0000 - val_loss: 317867648.0000\n",
      "Epoch 734/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1056290240.0000 - val_loss: 317316896.0000\n",
      "Epoch 735/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1054710720.0000 - val_loss: 316765856.0000\n",
      "Epoch 736/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1053129920.0000 - val_loss: 316214560.0000\n",
      "Epoch 737/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1051547776.0000 - val_loss: 315662912.0000\n",
      "Epoch 738/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1049964736.0000 - val_loss: 315111104.0000\n",
      "Epoch 739/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1048380416.0000 - val_loss: 314558880.0000\n",
      "Epoch 740/200000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1046794880.0000 - val_loss: 314006496.0000\n",
      "Epoch 741/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1045208128.0000 - val_loss: 313453792.0000\n",
      "Epoch 742/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1043620352.0000 - val_loss: 312900896.0000\n",
      "Epoch 743/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1042031488.0000 - val_loss: 312347744.0000\n",
      "Epoch 744/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1040441472.0000 - val_loss: 311794400.0000\n",
      "Epoch 745/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1038850432.0000 - val_loss: 311240736.0000\n",
      "Epoch 746/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1037258240.0000 - val_loss: 310686880.0000\n",
      "Epoch 747/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1035665216.0000 - val_loss: 310132832.0000\n",
      "Epoch 748/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1034070848.0000 - val_loss: 309578560.0000\n",
      "Epoch 749/200000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1032475648.0000 - val_loss: 309024032.0000\n",
      "Epoch 750/200000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1030879616.0000 - val_loss: 308469408.0000\n",
      "Epoch 751/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1029282368.0000 - val_loss: 307914496.0000\n",
      "Epoch 752/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1027684096.0000 - val_loss: 307359456.0000\n",
      "Epoch 753/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1026084800.0000 - val_loss: 306804256.0000\n",
      "Epoch 754/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1024484864.0000 - val_loss: 306248800.0000\n",
      "Epoch 755/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1022883904.0000 - val_loss: 305693248.0000\n",
      "Epoch 756/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1021281856.0000 - val_loss: 305137504.0000\n",
      "Epoch 757/200000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1019679104.0000 - val_loss: 304581632.0000\n",
      "Epoch 758/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1018075264.0000 - val_loss: 304025568.0000\n",
      "Epoch 759/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1016470784.0000 - val_loss: 303469408.0000\n",
      "Epoch 760/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1014865536.0000 - val_loss: 302913056.0000\n",
      "Epoch 761/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1013259264.0000 - val_loss: 302356640.0000\n",
      "Epoch 762/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1011652224.0000 - val_loss: 301800064.0000\n",
      "Epoch 763/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1010044288.0000 - val_loss: 301243424.0000\n",
      "Epoch 764/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1008435904.0000 - val_loss: 300686560.0000\n",
      "Epoch 765/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1006826368.0000 - val_loss: 300129632.0000\n",
      "Epoch 766/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1005216384.0000 - val_loss: 299572640.0000\n",
      "Epoch 767/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1003605440.0000 - val_loss: 299015584.0000\n",
      "Epoch 768/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1001993792.0000 - val_loss: 298458400.0000\n",
      "Epoch 769/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1000381440.0000 - val_loss: 297901152.0000\n",
      "Epoch 770/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 998768576.0000 - val_loss: 297343840.0000\n",
      "Epoch 771/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 997154880.0000 - val_loss: 296786464.0000\n",
      "Epoch 772/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 995540672.0000 - val_loss: 296228992.0000\n",
      "Epoch 773/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 993925696.0000 - val_loss: 295671552.0000\n",
      "Epoch 774/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 992310080.0000 - val_loss: 295113984.0000\n",
      "Epoch 775/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 990693888.0000 - val_loss: 294556416.0000\n",
      "Epoch 776/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 989077184.0000 - val_loss: 293998752.0000\n",
      "Epoch 777/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 987459840.0000 - val_loss: 293441120.0000\n",
      "Epoch 778/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 985841984.0000 - val_loss: 292883424.0000\n",
      "Epoch 779/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 984223616.0000 - val_loss: 292325760.0000\n",
      "Epoch 780/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 982604544.0000 - val_loss: 291768064.0000\n",
      "Epoch 781/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 980985088.0000 - val_loss: 291210368.0000\n",
      "Epoch 782/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 979365120.0000 - val_loss: 290652640.0000\n",
      "Epoch 783/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 977744640.0000 - val_loss: 290094976.0000\n",
      "Epoch 784/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 976123840.0000 - val_loss: 289537312.0000\n",
      "Epoch 785/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 974502528.0000 - val_loss: 288979680.0000\n",
      "Epoch 786/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 972880640.0000 - val_loss: 288422016.0000\n",
      "Epoch 787/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 971258496.0000 - val_loss: 287864416.0000\n",
      "Epoch 788/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 969635904.0000 - val_loss: 287306880.0000\n",
      "Epoch 789/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 968012992.0000 - val_loss: 286749376.0000\n",
      "Epoch 790/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 966389632.0000 - val_loss: 286191968.0000\n",
      "Epoch 791/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 964766016.0000 - val_loss: 285634560.0000\n",
      "Epoch 792/200000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 963141952.0000 - val_loss: 285077248.0000\n",
      "Epoch 793/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 961517824.0000 - val_loss: 284520032.0000\n",
      "Epoch 794/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 959893120.0000 - val_loss: 283962912.0000\n",
      "Epoch 795/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 958268288.0000 - val_loss: 283405792.0000\n",
      "Epoch 796/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 956643136.0000 - val_loss: 282848832.0000\n",
      "Epoch 797/200000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 955017792.0000 - val_loss: 282291936.0000\n",
      "Epoch 798/200000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 953392256.0000 - val_loss: 281735168.0000\n",
      "Epoch 799/200000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 951766464.0000 - val_loss: 281178496.0000\n",
      "Epoch 800/200000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 950140416.0000 - val_loss: 280621984.0000\n",
      "Epoch 801/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 948514112.0000 - val_loss: 280065600.0000\n",
      "Epoch 802/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 946887872.0000 - val_loss: 279509312.0000\n",
      "Epoch 803/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 945261376.0000 - val_loss: 278953184.0000\n",
      "Epoch 804/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 943634816.0000 - val_loss: 278397152.0000\n",
      "Epoch 805/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 942008064.0000 - val_loss: 277841312.0000\n",
      "Epoch 806/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 940381248.0000 - val_loss: 277285664.0000\n",
      "Epoch 807/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 938754432.0000 - val_loss: 276730080.0000\n",
      "Epoch 808/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 937127424.0000 - val_loss: 276174720.0000\n",
      "Epoch 809/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 935500352.0000 - val_loss: 275619584.0000\n",
      "Epoch 810/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 933873408.0000 - val_loss: 275064576.0000\n",
      "Epoch 811/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 932246272.0000 - val_loss: 274509760.0000\n",
      "Epoch 812/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 930619328.0000 - val_loss: 273955168.0000\n",
      "Epoch 813/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 928992320.0000 - val_loss: 273400768.0000\n",
      "Epoch 814/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 927365312.0000 - val_loss: 272846592.0000\n",
      "Epoch 815/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 925738432.0000 - val_loss: 272292576.0000\n",
      "Epoch 816/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 924111616.0000 - val_loss: 271738784.0000\n",
      "Epoch 817/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 922484800.0000 - val_loss: 271185280.0000\n",
      "Epoch 818/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 920858176.0000 - val_loss: 270631968.0000\n",
      "Epoch 819/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 919231616.0000 - val_loss: 270078880.0000\n",
      "Epoch 820/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 917605312.0000 - val_loss: 269526080.0000\n",
      "Epoch 821/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 915979072.0000 - val_loss: 268973504.0000\n",
      "Epoch 822/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 914352896.0000 - val_loss: 268421216.0000\n",
      "Epoch 823/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 912727040.0000 - val_loss: 267869200.0000\n",
      "Epoch 824/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 911101312.0000 - val_loss: 267317424.0000\n",
      "Epoch 825/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 909475904.0000 - val_loss: 266765984.0000\n",
      "Epoch 826/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 907850752.0000 - val_loss: 266214816.0000\n",
      "Epoch 827/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 906225856.0000 - val_loss: 265663904.0000\n",
      "Epoch 828/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 904601152.0000 - val_loss: 265113312.0000\n",
      "Epoch 829/200000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 902976768.0000 - val_loss: 264563072.0000\n",
      "Epoch 830/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 901352768.0000 - val_loss: 264013072.0000\n",
      "Epoch 831/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 899728896.0000 - val_loss: 263463440.0000\n",
      "Epoch 832/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 898105472.0000 - val_loss: 262914112.0000\n",
      "Epoch 833/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 896482432.0000 - val_loss: 262365120.0000\n",
      "Epoch 834/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 894859712.0000 - val_loss: 261816496.0000\n",
      "Epoch 835/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 893237632.0000 - val_loss: 261268192.0000\n",
      "Epoch 836/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 891615488.0000 - val_loss: 260720240.0000\n",
      "Epoch 837/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 889994176.0000 - val_loss: 260172704.0000\n",
      "Epoch 838/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 888373120.0000 - val_loss: 259625472.0000\n",
      "Epoch 839/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 886752640.0000 - val_loss: 259078688.0000\n",
      "Epoch 840/200000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 885132608.0000 - val_loss: 258532240.0000\n",
      "Epoch 841/200000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 883512960.0000 - val_loss: 257986208.0000\n",
      "Epoch 842/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 881893824.0000 - val_loss: 257440544.0000\n",
      "Epoch 843/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 880275264.0000 - val_loss: 256895312.0000\n",
      "Epoch 844/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 878657216.0000 - val_loss: 256350496.0000\n",
      "Epoch 845/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 877039744.0000 - val_loss: 255806048.0000\n",
      "Epoch 846/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 875422912.0000 - val_loss: 255262048.0000\n",
      "Epoch 847/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 873806656.0000 - val_loss: 254718496.0000\n",
      "Epoch 848/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 872190912.0000 - val_loss: 254175360.0000\n",
      "Epoch 849/200000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 870575872.0000 - val_loss: 253632672.0000\n",
      "Epoch 850/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 868961536.0000 - val_loss: 253090384.0000\n",
      "Epoch 851/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 867347776.0000 - val_loss: 252548624.0000\n",
      "Epoch 852/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 865734720.0000 - val_loss: 252007296.0000\n",
      "Epoch 853/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 864122304.0000 - val_loss: 251466416.0000\n",
      "Epoch 854/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 862510656.0000 - val_loss: 250926032.0000\n",
      "Epoch 855/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 860899648.0000 - val_loss: 250386096.0000\n",
      "Epoch 856/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 859289536.0000 - val_loss: 249846656.0000\n",
      "Epoch 857/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 857680128.0000 - val_loss: 249307744.0000\n",
      "Epoch 858/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 856071424.0000 - val_loss: 248769344.0000\n",
      "Epoch 859/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 854463360.0000 - val_loss: 248231440.0000\n",
      "Epoch 860/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 852856320.0000 - val_loss: 247694048.0000\n",
      "Epoch 861/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 851250112.0000 - val_loss: 247157184.0000\n",
      "Epoch 862/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 849644672.0000 - val_loss: 246620864.0000\n",
      "Epoch 863/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 848040128.0000 - val_loss: 246085072.0000\n",
      "Epoch 864/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 846436352.0000 - val_loss: 245549776.0000\n",
      "Epoch 865/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 844833600.0000 - val_loss: 245015056.0000\n",
      "Epoch 866/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 843231744.0000 - val_loss: 244480864.0000\n",
      "Epoch 867/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 841630656.0000 - val_loss: 243947248.0000\n",
      "Epoch 868/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 840030656.0000 - val_loss: 243414208.0000\n",
      "Epoch 869/200000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 838431424.0000 - val_loss: 242881712.0000\n",
      "Epoch 870/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 836833472.0000 - val_loss: 242349776.0000\n",
      "Epoch 871/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 835236352.0000 - val_loss: 241818464.0000\n",
      "Epoch 872/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 833640128.0000 - val_loss: 241287744.0000\n",
      "Epoch 873/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 832045056.0000 - val_loss: 240757568.0000\n",
      "Epoch 874/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 830451008.0000 - val_loss: 240228000.0000\n",
      "Epoch 875/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 828858048.0000 - val_loss: 239699056.0000\n",
      "Epoch 876/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 827265984.0000 - val_loss: 239170736.0000\n",
      "Epoch 877/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 825675328.0000 - val_loss: 238643008.0000\n",
      "Epoch 878/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 824085440.0000 - val_loss: 238115904.0000\n",
      "Epoch 879/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 822496768.0000 - val_loss: 237589408.0000\n",
      "Epoch 880/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 820909312.0000 - val_loss: 237063520.0000\n",
      "Epoch 881/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 819322944.0000 - val_loss: 236538304.0000\n",
      "Epoch 882/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 817737792.0000 - val_loss: 236013744.0000\n",
      "Epoch 883/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 816153920.0000 - val_loss: 235489808.0000\n",
      "Epoch 884/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 814571072.0000 - val_loss: 234966560.0000\n",
      "Epoch 885/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 812989440.0000 - val_loss: 234443952.0000\n",
      "Epoch 886/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 811409088.0000 - val_loss: 233922000.0000\n",
      "Epoch 887/200000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 809830144.0000 - val_loss: 233400736.0000\n",
      "Epoch 888/200000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 808252224.0000 - val_loss: 232880160.0000\n",
      "Epoch 889/200000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 806675648.0000 - val_loss: 232360288.0000\n",
      "Epoch 890/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 805100416.0000 - val_loss: 231841104.0000\n",
      "Epoch 891/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 803526528.0000 - val_loss: 231322544.0000\n",
      "Epoch 892/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 801953920.0000 - val_loss: 230804768.0000\n",
      "Epoch 893/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 800382656.0000 - val_loss: 230287680.0000\n",
      "Epoch 894/200000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 798812736.0000 - val_loss: 229771296.0000\n",
      "Epoch 895/200000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 797244224.0000 - val_loss: 229255632.0000\n",
      "Epoch 896/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 795677120.0000 - val_loss: 228740704.0000\n",
      "Epoch 897/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 794111424.0000 - val_loss: 228226496.0000\n",
      "Epoch 898/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 792547136.0000 - val_loss: 227713056.0000\n",
      "Epoch 899/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 790984320.0000 - val_loss: 227200384.0000\n",
      "Epoch 900/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 789422912.0000 - val_loss: 226688432.0000\n",
      "Epoch 901/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 787862784.0000 - val_loss: 226177200.0000\n",
      "Epoch 902/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 786304320.0000 - val_loss: 225666784.0000\n",
      "Epoch 903/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 784747520.0000 - val_loss: 225157152.0000\n",
      "Epoch 904/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 783192128.0000 - val_loss: 224648288.0000\n",
      "Epoch 905/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 781638144.0000 - val_loss: 224140192.0000\n",
      "Epoch 906/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 780085760.0000 - val_loss: 223632928.0000\n",
      "Epoch 907/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 778534912.0000 - val_loss: 223126432.0000\n",
      "Epoch 908/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 776985728.0000 - val_loss: 222620736.0000\n",
      "Epoch 909/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 775438080.0000 - val_loss: 222115856.0000\n",
      "Epoch 910/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 773892032.0000 - val_loss: 221611808.0000\n",
      "Epoch 911/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 772347648.0000 - val_loss: 221108592.0000\n",
      "Epoch 912/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 770804992.0000 - val_loss: 220606160.0000\n",
      "Epoch 913/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 769263680.0000 - val_loss: 220104592.0000\n",
      "Epoch 914/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 767724224.0000 - val_loss: 219603824.0000\n",
      "Epoch 915/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 766186432.0000 - val_loss: 219103904.0000\n",
      "Epoch 916/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 764650432.0000 - val_loss: 218604864.0000\n",
      "Epoch 917/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 763116096.0000 - val_loss: 218106608.0000\n",
      "Epoch 918/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 761583488.0000 - val_loss: 217609248.0000\n",
      "Epoch 919/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 760052608.0000 - val_loss: 217112736.0000\n",
      "Epoch 920/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 758523456.0000 - val_loss: 216617120.0000\n",
      "Epoch 921/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 756996032.0000 - val_loss: 216122352.0000\n",
      "Epoch 922/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 755470592.0000 - val_loss: 215628448.0000\n",
      "Epoch 923/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 753946816.0000 - val_loss: 215135456.0000\n",
      "Epoch 924/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 752424768.0000 - val_loss: 214643328.0000\n",
      "Epoch 925/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 750904640.0000 - val_loss: 214152096.0000\n",
      "Epoch 926/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 749386496.0000 - val_loss: 213661744.0000\n",
      "Epoch 927/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 747870080.0000 - val_loss: 213172320.0000\n",
      "Epoch 928/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 746355520.0000 - val_loss: 212683776.0000\n",
      "Epoch 929/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 744842816.0000 - val_loss: 212196160.0000\n",
      "Epoch 930/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 743332288.0000 - val_loss: 211709488.0000\n",
      "Epoch 931/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 741823424.0000 - val_loss: 211223712.0000\n",
      "Epoch 932/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 740316608.0000 - val_loss: 210738832.0000\n",
      "Epoch 933/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 738811712.0000 - val_loss: 210254912.0000\n",
      "Epoch 934/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 737308736.0000 - val_loss: 209771936.0000\n",
      "Epoch 935/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 735807744.0000 - val_loss: 209289872.0000\n",
      "Epoch 936/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 734308736.0000 - val_loss: 208808816.0000\n",
      "Epoch 937/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 732811776.0000 - val_loss: 208328656.0000\n",
      "Epoch 938/200000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 731316864.0000 - val_loss: 207849488.0000\n",
      "Epoch 939/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 729823936.0000 - val_loss: 207371248.0000\n",
      "Epoch 940/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 728333120.0000 - val_loss: 206893984.0000\n",
      "Epoch 941/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 726844352.0000 - val_loss: 206417744.0000\n",
      "Epoch 942/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 725357504.0000 - val_loss: 205942432.0000\n",
      "Epoch 943/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 723872896.0000 - val_loss: 205468144.0000\n",
      "Epoch 944/200000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 722390336.0000 - val_loss: 204994880.0000\n",
      "Epoch 945/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 720909952.0000 - val_loss: 204522560.0000\n",
      "Epoch 946/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 719431552.0000 - val_loss: 204051312.0000\n",
      "Epoch 947/200000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 717955328.0000 - val_loss: 203580976.0000\n",
      "Epoch 948/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 716481344.0000 - val_loss: 203111760.0000\n",
      "Epoch 949/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 715009472.0000 - val_loss: 202643520.0000\n",
      "Epoch 950/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 713539776.0000 - val_loss: 202176304.0000\n",
      "Epoch 951/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 712072384.0000 - val_loss: 201710144.0000\n",
      "Epoch 952/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 710607168.0000 - val_loss: 201244976.0000\n",
      "Epoch 953/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 709144128.0000 - val_loss: 200780848.0000\n",
      "Epoch 954/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 707683264.0000 - val_loss: 200317776.0000\n",
      "Epoch 955/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 706224768.0000 - val_loss: 199855712.0000\n",
      "Epoch 956/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 704768448.0000 - val_loss: 199394736.0000\n",
      "Epoch 957/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 703314496.0000 - val_loss: 198934800.0000\n",
      "Epoch 958/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 701862784.0000 - val_loss: 198475872.0000\n",
      "Epoch 959/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 700413376.0000 - val_loss: 198018096.0000\n",
      "Epoch 960/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 698966208.0000 - val_loss: 197561312.0000\n",
      "Epoch 961/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 697521472.0000 - val_loss: 197105664.0000\n",
      "Epoch 962/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 696078976.0000 - val_loss: 196651056.0000\n",
      "Epoch 963/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 694639040.0000 - val_loss: 196197520.0000\n",
      "Epoch 964/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 693201280.0000 - val_loss: 195745120.0000\n",
      "Epoch 965/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 691765952.0000 - val_loss: 195293712.0000\n",
      "Epoch 966/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 690332992.0000 - val_loss: 194843456.0000\n",
      "Epoch 967/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 688902464.0000 - val_loss: 194394304.0000\n",
      "Epoch 968/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 687474432.0000 - val_loss: 193946240.0000\n",
      "Epoch 969/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 686048640.0000 - val_loss: 193499280.0000\n",
      "Epoch 970/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 684625408.0000 - val_loss: 193053392.0000\n",
      "Epoch 971/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 683204608.0000 - val_loss: 192608672.0000\n",
      "Epoch 972/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 681786304.0000 - val_loss: 192165024.0000\n",
      "Epoch 973/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 680370496.0000 - val_loss: 191722512.0000\n",
      "Epoch 974/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 678957184.0000 - val_loss: 191281136.0000\n",
      "Epoch 975/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 677546304.0000 - val_loss: 190840880.0000\n",
      "Epoch 976/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 676137984.0000 - val_loss: 190401760.0000\n",
      "Epoch 977/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 674732032.0000 - val_loss: 189963760.0000\n",
      "Epoch 978/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 673328768.0000 - val_loss: 189526896.0000\n",
      "Epoch 979/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 671928128.0000 - val_loss: 189091184.0000\n",
      "Epoch 980/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 670530048.0000 - val_loss: 188656640.0000\n",
      "Epoch 981/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 669134336.0000 - val_loss: 188223200.0000\n",
      "Epoch 982/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 667741312.0000 - val_loss: 187790960.0000\n",
      "Epoch 983/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 666350976.0000 - val_loss: 187359856.0000\n",
      "Epoch 984/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 664963136.0000 - val_loss: 186929904.0000\n",
      "Epoch 985/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 663577984.0000 - val_loss: 186501136.0000\n",
      "Epoch 986/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 662195328.0000 - val_loss: 186073520.0000\n",
      "Epoch 987/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 660815488.0000 - val_loss: 185647088.0000\n",
      "Epoch 988/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 659438208.0000 - val_loss: 185221840.0000\n",
      "Epoch 989/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 658063616.0000 - val_loss: 184797744.0000\n",
      "Epoch 990/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 656691712.0000 - val_loss: 184374800.0000\n",
      "Epoch 991/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 655322432.0000 - val_loss: 183953088.0000\n",
      "Epoch 992/200000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 653955904.0000 - val_loss: 183532560.0000\n",
      "Epoch 993/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 652592064.0000 - val_loss: 183113232.0000\n",
      "Epoch 994/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 651230912.0000 - val_loss: 182695072.0000\n",
      "Epoch 995/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 649872576.0000 - val_loss: 182278128.0000\n",
      "Epoch 996/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 648516864.0000 - val_loss: 181862416.0000\n",
      "Epoch 997/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 647163968.0000 - val_loss: 181447872.0000\n",
      "Epoch 998/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 645813888.0000 - val_loss: 181034544.0000\n",
      "Epoch 999/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 644466432.0000 - val_loss: 180622432.0000\n",
      "Epoch 1000/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 643121856.0000 - val_loss: 180211568.0000\n",
      "Epoch 1001/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 641780032.0000 - val_loss: 179801936.0000\n",
      "Epoch 1002/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 640440960.0000 - val_loss: 179393440.0000\n",
      "Epoch 1003/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 639104768.0000 - val_loss: 178986256.0000\n",
      "Epoch 1004/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 637771328.0000 - val_loss: 178580272.0000\n",
      "Epoch 1005/200000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 636440832.0000 - val_loss: 178175504.0000\n",
      "Epoch 1006/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 635113088.0000 - val_loss: 177772000.0000\n",
      "Epoch 1007/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 633788224.0000 - val_loss: 177369728.0000\n",
      "Epoch 1008/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 632466240.0000 - val_loss: 176968688.0000\n",
      "Epoch 1009/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 631147008.0000 - val_loss: 176568896.0000\n",
      "Epoch 1010/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 629830848.0000 - val_loss: 176170384.0000\n",
      "Epoch 1011/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 628517312.0000 - val_loss: 175773072.0000\n",
      "Epoch 1012/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 627206912.0000 - val_loss: 175377008.0000\n",
      "Epoch 1013/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 625899456.0000 - val_loss: 174982240.0000\n",
      "Epoch 1014/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 624594688.0000 - val_loss: 174588704.0000\n",
      "Epoch 1015/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 623292992.0000 - val_loss: 174196432.0000\n",
      "Epoch 1016/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 621994112.0000 - val_loss: 173805440.0000\n",
      "Epoch 1017/200000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 620698304.0000 - val_loss: 173415744.0000\n",
      "Epoch 1018/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 619405376.0000 - val_loss: 173027312.0000\n",
      "Epoch 1019/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 618115392.0000 - val_loss: 172640160.0000\n",
      "Epoch 1020/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 616828352.0000 - val_loss: 172254304.0000\n",
      "Epoch 1021/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 615544320.0000 - val_loss: 171869696.0000\n",
      "Epoch 1022/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 614263232.0000 - val_loss: 171486368.0000\n",
      "Epoch 1023/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 612985152.0000 - val_loss: 171104384.0000\n",
      "Epoch 1024/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 611710144.0000 - val_loss: 170723680.0000\n",
      "Epoch 1025/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 610438080.0000 - val_loss: 170344256.0000\n",
      "Epoch 1026/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 609169024.0000 - val_loss: 169966112.0000\n",
      "Epoch 1027/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 607903104.0000 - val_loss: 169589280.0000\n",
      "Epoch 1028/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 606640064.0000 - val_loss: 169213744.0000\n",
      "Epoch 1029/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 605380160.0000 - val_loss: 168839504.0000\n",
      "Epoch 1030/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 604123264.0000 - val_loss: 168466560.0000\n",
      "Epoch 1031/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 602869504.0000 - val_loss: 168094960.0000\n",
      "Epoch 1032/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 601618624.0000 - val_loss: 167724624.0000\n",
      "Epoch 1033/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 600371008.0000 - val_loss: 167355600.0000\n",
      "Epoch 1034/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 599126400.0000 - val_loss: 166987904.0000\n",
      "Epoch 1035/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 597884864.0000 - val_loss: 166621504.0000\n",
      "Epoch 1036/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 596646464.0000 - val_loss: 166256416.0000\n",
      "Epoch 1037/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 595411008.0000 - val_loss: 165892656.0000\n",
      "Epoch 1038/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 594178880.0000 - val_loss: 165530208.0000\n",
      "Epoch 1039/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 592949760.0000 - val_loss: 165169056.0000\n",
      "Epoch 1040/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 591723776.0000 - val_loss: 164809248.0000\n",
      "Epoch 1041/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 590500864.0000 - val_loss: 164450768.0000\n",
      "Epoch 1042/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 589281216.0000 - val_loss: 164093584.0000\n",
      "Epoch 1043/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 588064640.0000 - val_loss: 163737712.0000\n",
      "Epoch 1044/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 586851264.0000 - val_loss: 163383200.0000\n",
      "Epoch 1045/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 585641024.0000 - val_loss: 163030016.0000\n",
      "Epoch 1046/200000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 584433856.0000 - val_loss: 162678160.0000\n",
      "Epoch 1047/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 583229952.0000 - val_loss: 162327616.0000\n",
      "Epoch 1048/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 582029248.0000 - val_loss: 161978416.0000\n",
      "Epoch 1049/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 580831680.0000 - val_loss: 161630560.0000\n",
      "Epoch 1050/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 579637312.0000 - val_loss: 161284000.0000\n",
      "Epoch 1051/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 578446080.0000 - val_loss: 160938816.0000\n",
      "Epoch 1052/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 577258176.0000 - val_loss: 160594960.0000\n",
      "Epoch 1053/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 576073344.0000 - val_loss: 160252448.0000\n",
      "Epoch 1054/200000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 574891904.0000 - val_loss: 159911312.0000\n",
      "Epoch 1055/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 573713472.0000 - val_loss: 159571504.0000\n",
      "Epoch 1056/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 572538240.0000 - val_loss: 159233056.0000\n",
      "Epoch 1057/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 571366464.0000 - val_loss: 158895984.0000\n",
      "Epoch 1058/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 570197824.0000 - val_loss: 158560256.0000\n",
      "Epoch 1059/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 569032192.0000 - val_loss: 158225872.0000\n",
      "Epoch 1060/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 567870144.0000 - val_loss: 157892848.0000\n",
      "Epoch 1061/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 566711040.0000 - val_loss: 157561184.0000\n",
      "Epoch 1062/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 565555456.0000 - val_loss: 157230912.0000\n",
      "Epoch 1063/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 564402944.0000 - val_loss: 156901936.0000\n",
      "Epoch 1064/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 563253760.0000 - val_loss: 156574336.0000\n",
      "Epoch 1065/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 562107840.0000 - val_loss: 156248128.0000\n",
      "Epoch 1066/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 560965120.0000 - val_loss: 155923280.0000\n",
      "Epoch 1067/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 559825792.0000 - val_loss: 155599792.0000\n",
      "Epoch 1068/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 558689600.0000 - val_loss: 155277648.0000\n",
      "Epoch 1069/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 557556928.0000 - val_loss: 154956880.0000\n",
      "Epoch 1070/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 556427328.0000 - val_loss: 154637456.0000\n",
      "Epoch 1071/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 555301120.0000 - val_loss: 154319456.0000\n",
      "Epoch 1072/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 554178112.0000 - val_loss: 154002752.0000\n",
      "Epoch 1073/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 553058368.0000 - val_loss: 153687456.0000\n",
      "Epoch 1074/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 551942144.0000 - val_loss: 153373536.0000\n",
      "Epoch 1075/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 550829056.0000 - val_loss: 153060944.0000\n",
      "Epoch 1076/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 549719296.0000 - val_loss: 152749744.0000\n",
      "Epoch 1077/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 548612864.0000 - val_loss: 152439904.0000\n",
      "Epoch 1078/200000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 547509760.0000 - val_loss: 152131472.0000\n",
      "Epoch 1079/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 546410048.0000 - val_loss: 151824384.0000\n",
      "Epoch 1080/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 545313536.0000 - val_loss: 151518672.0000\n",
      "Epoch 1081/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 544220480.0000 - val_loss: 151214320.0000\n",
      "Epoch 1082/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 543130688.0000 - val_loss: 150911360.0000\n",
      "Epoch 1083/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 542044224.0000 - val_loss: 150609728.0000\n",
      "Epoch 1084/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 540961152.0000 - val_loss: 150309472.0000\n",
      "Epoch 1085/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 539881408.0000 - val_loss: 150010592.0000\n",
      "Epoch 1086/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 538804992.0000 - val_loss: 149713088.0000\n",
      "Epoch 1087/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 537732032.0000 - val_loss: 149416976.0000\n",
      "Epoch 1088/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 536662368.0000 - val_loss: 149122176.0000\n",
      "Epoch 1089/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 535596000.0000 - val_loss: 148828768.0000\n",
      "Epoch 1090/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 534532992.0000 - val_loss: 148536720.0000\n",
      "Epoch 1091/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 533473408.0000 - val_loss: 148246048.0000\n",
      "Epoch 1092/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 532417152.0000 - val_loss: 147956736.0000\n",
      "Epoch 1093/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 531364320.0000 - val_loss: 147668784.0000\n",
      "Epoch 1094/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 530314752.0000 - val_loss: 147382176.0000\n",
      "Epoch 1095/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 529268672.0000 - val_loss: 147096928.0000\n",
      "Epoch 1096/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 528225920.0000 - val_loss: 146813040.0000\n",
      "Epoch 1097/200000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 527186592.0000 - val_loss: 146530576.0000\n",
      "Epoch 1098/200000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 526150592.0000 - val_loss: 146249392.0000\n",
      "Epoch 1099/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 525117952.0000 - val_loss: 145969616.0000\n",
      "Epoch 1100/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 524088704.0000 - val_loss: 145691232.0000\n",
      "Epoch 1101/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 523062912.0000 - val_loss: 145414176.0000\n",
      "Epoch 1102/200000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 522040448.0000 - val_loss: 145138480.0000\n",
      "Epoch 1103/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 521021312.0000 - val_loss: 144864160.0000\n",
      "Epoch 1104/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 520005600.0000 - val_loss: 144591232.0000\n",
      "Epoch 1105/200000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 518993312.0000 - val_loss: 144319664.0000\n",
      "Epoch 1106/200000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 517984384.0000 - val_loss: 144049392.0000\n",
      "Epoch 1107/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 516978912.0000 - val_loss: 143780544.0000\n",
      "Epoch 1108/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 515976800.0000 - val_loss: 143513040.0000\n",
      "Epoch 1109/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 514978048.0000 - val_loss: 143246896.0000\n",
      "Epoch 1110/200000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 513982688.0000 - val_loss: 142982096.0000\n",
      "Epoch 1111/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 512990720.0000 - val_loss: 142718688.0000\n",
      "Epoch 1112/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 512002272.0000 - val_loss: 142456624.0000\n",
      "Epoch 1113/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 511017056.0000 - val_loss: 142195888.0000\n",
      "Epoch 1114/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 510035264.0000 - val_loss: 141936560.0000\n",
      "Epoch 1115/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 509056992.0000 - val_loss: 141678560.0000\n",
      "Epoch 1116/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 508082048.0000 - val_loss: 141421904.0000\n",
      "Epoch 1117/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 507110400.0000 - val_loss: 141166608.0000\n",
      "Epoch 1118/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 506142272.0000 - val_loss: 140912672.0000\n",
      "Epoch 1119/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 505177440.0000 - val_loss: 140660080.0000\n",
      "Epoch 1120/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 504216160.0000 - val_loss: 140408864.0000\n",
      "Epoch 1121/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 503258208.0000 - val_loss: 140158960.0000\n",
      "Epoch 1122/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 502303552.0000 - val_loss: 139910448.0000\n",
      "Epoch 1123/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 501352320.0000 - val_loss: 139663216.0000\n",
      "Epoch 1124/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 500404608.0000 - val_loss: 139417328.0000\n",
      "Epoch 1125/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 499460224.0000 - val_loss: 139172800.0000\n",
      "Epoch 1126/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 498519136.0000 - val_loss: 138929616.0000\n",
      "Epoch 1127/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 497581472.0000 - val_loss: 138687760.0000\n",
      "Epoch 1128/200000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 496647296.0000 - val_loss: 138447232.0000\n",
      "Epoch 1129/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 495716480.0000 - val_loss: 138208080.0000\n",
      "Epoch 1130/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 494788992.0000 - val_loss: 137970224.0000\n",
      "Epoch 1131/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 493864864.0000 - val_loss: 137733760.0000\n",
      "Epoch 1132/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 492944128.0000 - val_loss: 137498640.0000\n",
      "Epoch 1133/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 492026784.0000 - val_loss: 137264832.0000\n",
      "Epoch 1134/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 491112896.0000 - val_loss: 137032400.0000\n",
      "Epoch 1135/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 490202304.0000 - val_loss: 136801296.0000\n",
      "Epoch 1136/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 489295168.0000 - val_loss: 136571520.0000\n",
      "Epoch 1137/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 488391328.0000 - val_loss: 136343104.0000\n",
      "Epoch 1138/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 487490816.0000 - val_loss: 136116000.0000\n",
      "Epoch 1139/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 486593792.0000 - val_loss: 135890240.0000\n",
      "Epoch 1140/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 485700096.0000 - val_loss: 135665792.0000\n",
      "Epoch 1141/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 484809696.0000 - val_loss: 135442704.0000\n",
      "Epoch 1142/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 483922720.0000 - val_loss: 135220912.0000\n",
      "Epoch 1143/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 483039168.0000 - val_loss: 135000448.0000\n",
      "Epoch 1144/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 482158944.0000 - val_loss: 134781296.0000\n",
      "Epoch 1145/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 481282080.0000 - val_loss: 134563488.0000\n",
      "Epoch 1146/200000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 480408544.0000 - val_loss: 134346960.0000\n",
      "Epoch 1147/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 479538400.0000 - val_loss: 134131768.0000\n",
      "Epoch 1148/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 478671616.0000 - val_loss: 133917864.0000\n",
      "Epoch 1149/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 477808224.0000 - val_loss: 133705288.0000\n",
      "Epoch 1150/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 476948160.0000 - val_loss: 133493984.0000\n",
      "Epoch 1151/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 476091424.0000 - val_loss: 133283984.0000\n",
      "Epoch 1152/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 475237952.0000 - val_loss: 133075288.0000\n",
      "Epoch 1153/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 474387872.0000 - val_loss: 132867904.0000\n",
      "Epoch 1154/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 473541152.0000 - val_loss: 132661840.0000\n",
      "Epoch 1155/200000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 472697760.0000 - val_loss: 132457072.0000\n",
      "Epoch 1156/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 471857568.0000 - val_loss: 132253608.0000\n",
      "Epoch 1157/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 471020704.0000 - val_loss: 132051432.0000\n",
      "Epoch 1158/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 470187200.0000 - val_loss: 131850568.0000\n",
      "Epoch 1159/200000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 469357088.0000 - val_loss: 131650976.0000\n",
      "Epoch 1160/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 468530176.0000 - val_loss: 131452680.0000\n",
      "Epoch 1161/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 467706528.0000 - val_loss: 131255672.0000\n",
      "Epoch 1162/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 466886272.0000 - val_loss: 131059936.0000\n",
      "Epoch 1163/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 466069344.0000 - val_loss: 130865496.0000\n",
      "Epoch 1164/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 465255680.0000 - val_loss: 130672312.0000\n",
      "Epoch 1165/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 464445376.0000 - val_loss: 130480408.0000\n",
      "Epoch 1166/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 463638272.0000 - val_loss: 130289760.0000\n",
      "Epoch 1167/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 462834560.0000 - val_loss: 130100392.0000\n",
      "Epoch 1168/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 462034016.0000 - val_loss: 129912240.0000\n",
      "Epoch 1169/200000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 461236768.0000 - val_loss: 129725392.0000\n",
      "Epoch 1170/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 460442912.0000 - val_loss: 129539800.0000\n",
      "Epoch 1171/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 459652320.0000 - val_loss: 129355464.0000\n",
      "Epoch 1172/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 458864864.0000 - val_loss: 129172384.0000\n",
      "Epoch 1173/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 458080832.0000 - val_loss: 128990520.0000\n",
      "Epoch 1174/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 457299872.0000 - val_loss: 128809936.0000\n",
      "Epoch 1175/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 456522336.0000 - val_loss: 128630576.0000\n",
      "Epoch 1176/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 455748096.0000 - val_loss: 128452440.0000\n",
      "Epoch 1177/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 454976992.0000 - val_loss: 128275560.0000\n",
      "Epoch 1178/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 454209184.0000 - val_loss: 128099872.0000\n",
      "Epoch 1179/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 453444576.0000 - val_loss: 127925464.0000\n",
      "Epoch 1180/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 452683232.0000 - val_loss: 127752208.0000\n",
      "Epoch 1181/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 451925056.0000 - val_loss: 127580208.0000\n",
      "Epoch 1182/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 451170240.0000 - val_loss: 127409408.0000\n",
      "Epoch 1183/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 450418560.0000 - val_loss: 127239824.0000\n",
      "Epoch 1184/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 449670144.0000 - val_loss: 127071448.0000\n",
      "Epoch 1185/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 448924864.0000 - val_loss: 126904312.0000\n",
      "Epoch 1186/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 448182880.0000 - val_loss: 126738352.0000\n",
      "Epoch 1187/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 447444000.0000 - val_loss: 126573600.0000\n",
      "Epoch 1188/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 446708384.0000 - val_loss: 126410048.0000\n",
      "Epoch 1189/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 445975872.0000 - val_loss: 126247704.0000\n",
      "Epoch 1190/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 445246592.0000 - val_loss: 126086560.0000\n",
      "Epoch 1191/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 444520544.0000 - val_loss: 125926584.0000\n",
      "Epoch 1192/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 443797600.0000 - val_loss: 125767784.0000\n",
      "Epoch 1193/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 443077888.0000 - val_loss: 125610184.0000\n",
      "Epoch 1194/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 442361216.0000 - val_loss: 125453768.0000\n",
      "Epoch 1195/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 441647872.0000 - val_loss: 125298520.0000\n",
      "Epoch 1196/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 440937504.0000 - val_loss: 125144464.0000\n",
      "Epoch 1197/200000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 440230336.0000 - val_loss: 124991528.0000\n",
      "Epoch 1198/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 439526400.0000 - val_loss: 124839776.0000\n",
      "Epoch 1199/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 438825504.0000 - val_loss: 124689208.0000\n",
      "Epoch 1200/200000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 438127744.0000 - val_loss: 124539760.0000\n",
      "Epoch 1201/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 437433216.0000 - val_loss: 124391480.0000\n",
      "Epoch 1202/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 436741536.0000 - val_loss: 124244376.0000\n",
      "Epoch 1203/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 436053184.0000 - val_loss: 124098368.0000\n",
      "Epoch 1204/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 435367968.0000 - val_loss: 123953568.0000\n",
      "Epoch 1205/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 434685696.0000 - val_loss: 123809832.0000\n",
      "Epoch 1206/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 434006528.0000 - val_loss: 123667280.0000\n",
      "Epoch 1207/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 433330432.0000 - val_loss: 123525832.0000\n",
      "Epoch 1208/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 432657472.0000 - val_loss: 123385520.0000\n",
      "Epoch 1209/200000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 431987552.0000 - val_loss: 123246320.0000\n",
      "Epoch 1210/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 431320704.0000 - val_loss: 123108232.0000\n",
      "Epoch 1211/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 430656928.0000 - val_loss: 122971232.0000\n",
      "Epoch 1212/200000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 429996160.0000 - val_loss: 122835352.0000\n",
      "Epoch 1213/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 429338304.0000 - val_loss: 122700576.0000\n",
      "Epoch 1214/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 428683680.0000 - val_loss: 122566920.0000\n",
      "Epoch 1215/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 428032032.0000 - val_loss: 122434352.0000\n",
      "Epoch 1216/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 427383296.0000 - val_loss: 122302880.0000\n",
      "Epoch 1217/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 426737664.0000 - val_loss: 122172464.0000\n",
      "Epoch 1218/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 426095040.0000 - val_loss: 122043184.0000\n",
      "Epoch 1219/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 425455392.0000 - val_loss: 121914976.0000\n",
      "Epoch 1220/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 424818720.0000 - val_loss: 121787840.0000\n",
      "Epoch 1221/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 424184960.0000 - val_loss: 121661784.0000\n",
      "Epoch 1222/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 423554272.0000 - val_loss: 121536792.0000\n",
      "Epoch 1223/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 422926496.0000 - val_loss: 121412880.0000\n",
      "Epoch 1224/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 422301728.0000 - val_loss: 121290008.0000\n",
      "Epoch 1225/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 421679872.0000 - val_loss: 121168200.0000\n",
      "Epoch 1226/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 421061024.0000 - val_loss: 121047448.0000\n",
      "Epoch 1227/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 420445024.0000 - val_loss: 120927736.0000\n",
      "Epoch 1228/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 419831904.0000 - val_loss: 120809064.0000\n",
      "Epoch 1229/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 419221856.0000 - val_loss: 120691432.0000\n",
      "Epoch 1230/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 418614656.0000 - val_loss: 120574856.0000\n",
      "Epoch 1231/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 418010336.0000 - val_loss: 120459288.0000\n",
      "Epoch 1232/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 417408928.0000 - val_loss: 120344784.0000\n",
      "Epoch 1233/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 416810400.0000 - val_loss: 120231248.0000\n",
      "Epoch 1234/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 416214688.0000 - val_loss: 120118768.0000\n",
      "Epoch 1235/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 415621920.0000 - val_loss: 120007280.0000\n",
      "Epoch 1236/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 415032000.0000 - val_loss: 119896832.0000\n",
      "Epoch 1237/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 414444896.0000 - val_loss: 119787328.0000\n",
      "Epoch 1238/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 413860800.0000 - val_loss: 119678888.0000\n",
      "Epoch 1239/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 413279392.0000 - val_loss: 119571416.0000\n",
      "Epoch 1240/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 412700800.0000 - val_loss: 119464944.0000\n",
      "Epoch 1241/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 412125056.0000 - val_loss: 119359448.0000\n",
      "Epoch 1242/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 411552192.0000 - val_loss: 119254976.0000\n",
      "Epoch 1243/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 410982080.0000 - val_loss: 119151440.0000\n",
      "Epoch 1244/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 410414688.0000 - val_loss: 119048920.0000\n",
      "Epoch 1245/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 409850208.0000 - val_loss: 118947336.0000\n",
      "Epoch 1246/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 409288480.0000 - val_loss: 118846736.0000\n",
      "Epoch 1247/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 408729472.0000 - val_loss: 118747096.0000\n",
      "Epoch 1248/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 408173216.0000 - val_loss: 118648416.0000\n",
      "Epoch 1249/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 407619776.0000 - val_loss: 118550712.0000\n",
      "Epoch 1250/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 407069056.0000 - val_loss: 118453936.0000\n",
      "Epoch 1251/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 406521056.0000 - val_loss: 118358112.0000\n",
      "Epoch 1252/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 405975776.0000 - val_loss: 118263232.0000\n",
      "Epoch 1253/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 405433248.0000 - val_loss: 118169280.0000\n",
      "Epoch 1254/200000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 404893376.0000 - val_loss: 118076272.0000\n",
      "Epoch 1255/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 404356192.0000 - val_loss: 117984184.0000\n",
      "Epoch 1256/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 403821728.0000 - val_loss: 117893024.0000\n",
      "Epoch 1257/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 403289856.0000 - val_loss: 117802776.0000\n",
      "Epoch 1258/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 402760704.0000 - val_loss: 117713440.0000\n",
      "Epoch 1259/200000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 402234272.0000 - val_loss: 117625032.0000\n",
      "Epoch 1260/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 401710464.0000 - val_loss: 117537520.0000\n",
      "Epoch 1261/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 401189280.0000 - val_loss: 117450912.0000\n",
      "Epoch 1262/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 400670720.0000 - val_loss: 117365192.0000\n",
      "Epoch 1263/200000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 400154784.0000 - val_loss: 117280368.0000\n",
      "Epoch 1264/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 399641472.0000 - val_loss: 117196424.0000\n",
      "Epoch 1265/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 399130816.0000 - val_loss: 117113360.0000\n",
      "Epoch 1266/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 398622784.0000 - val_loss: 117031168.0000\n",
      "Epoch 1267/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 398117280.0000 - val_loss: 116949848.0000\n",
      "Epoch 1268/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 397614368.0000 - val_loss: 116869408.0000\n",
      "Epoch 1269/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 397114016.0000 - val_loss: 116789824.0000\n",
      "Epoch 1270/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 396616256.0000 - val_loss: 116711080.0000\n",
      "Epoch 1271/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 396121024.0000 - val_loss: 116633192.0000\n",
      "Epoch 1272/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 395628352.0000 - val_loss: 116556144.0000\n",
      "Epoch 1273/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 395138240.0000 - val_loss: 116479960.0000\n",
      "Epoch 1274/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 394650624.0000 - val_loss: 116404584.0000\n",
      "Epoch 1275/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 394165472.0000 - val_loss: 116330048.0000\n",
      "Epoch 1276/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 393682880.0000 - val_loss: 116256376.0000\n",
      "Epoch 1277/200000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 393202912.0000 - val_loss: 116183512.0000\n",
      "Epoch 1278/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 392725216.0000 - val_loss: 116111464.0000\n",
      "Epoch 1279/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 392250048.0000 - val_loss: 116040216.0000\n",
      "Epoch 1280/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 391777472.0000 - val_loss: 115969768.0000\n",
      "Epoch 1281/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 391307264.0000 - val_loss: 115900136.0000\n",
      "Epoch 1282/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 390839520.0000 - val_loss: 115831288.0000\n",
      "Epoch 1283/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 390374176.0000 - val_loss: 115763240.0000\n",
      "Epoch 1284/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 389911328.0000 - val_loss: 115695992.0000\n",
      "Epoch 1285/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 389450816.0000 - val_loss: 115629528.0000\n",
      "Epoch 1286/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 388992768.0000 - val_loss: 115563824.0000\n",
      "Epoch 1287/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 388537120.0000 - val_loss: 115498912.0000\n",
      "Epoch 1288/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 388083904.0000 - val_loss: 115434776.0000\n",
      "Epoch 1289/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 387633088.0000 - val_loss: 115371400.0000\n",
      "Epoch 1290/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 387184576.0000 - val_loss: 115308792.0000\n",
      "Epoch 1291/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 386738400.0000 - val_loss: 115246912.0000\n",
      "Epoch 1292/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 386294528.0000 - val_loss: 115185808.0000\n",
      "Epoch 1293/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 385853184.0000 - val_loss: 115125456.0000\n",
      "Epoch 1294/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 385414080.0000 - val_loss: 115065824.0000\n",
      "Epoch 1295/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 384977248.0000 - val_loss: 115006944.0000\n",
      "Epoch 1296/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 384542848.0000 - val_loss: 114948784.0000\n",
      "Epoch 1297/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 384110656.0000 - val_loss: 114891352.0000\n",
      "Epoch 1298/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 383680768.0000 - val_loss: 114834624.0000\n",
      "Epoch 1299/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 383253184.0000 - val_loss: 114778608.0000\n",
      "Epoch 1300/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 382827840.0000 - val_loss: 114723304.0000\n",
      "Epoch 1301/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 382404800.0000 - val_loss: 114668680.0000\n",
      "Epoch 1302/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 381984000.0000 - val_loss: 114614768.0000\n",
      "Epoch 1303/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 381565472.0000 - val_loss: 114561552.0000\n",
      "Epoch 1304/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 381149184.0000 - val_loss: 114509024.0000\n",
      "Epoch 1305/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 380735040.0000 - val_loss: 114457184.0000\n",
      "Epoch 1306/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 380323136.0000 - val_loss: 114406032.0000\n",
      "Epoch 1307/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 379913504.0000 - val_loss: 114355536.0000\n",
      "Epoch 1308/200000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 379506016.0000 - val_loss: 114305736.0000\n",
      "Epoch 1309/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 379100704.0000 - val_loss: 114256592.0000\n",
      "Epoch 1310/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 378697536.0000 - val_loss: 114208096.0000\n",
      "Epoch 1311/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 378296672.0000 - val_loss: 114160280.0000\n",
      "Epoch 1312/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 377897952.0000 - val_loss: 114113088.0000\n",
      "Epoch 1313/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 377501248.0000 - val_loss: 114066536.0000\n",
      "Epoch 1314/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 377106784.0000 - val_loss: 114020632.0000\n",
      "Epoch 1315/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 376714400.0000 - val_loss: 113975360.0000\n",
      "Epoch 1316/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 376324160.0000 - val_loss: 113930728.0000\n",
      "Epoch 1317/200000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 375936000.0000 - val_loss: 113886712.0000\n",
      "Epoch 1318/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 375549920.0000 - val_loss: 113843360.0000\n",
      "Epoch 1319/200000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 375166048.0000 - val_loss: 113800600.0000\n",
      "Epoch 1320/200000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 374784160.0000 - val_loss: 113758440.0000\n",
      "Epoch 1321/200000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 374404384.0000 - val_loss: 113716904.0000\n",
      "Epoch 1322/200000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 374026656.0000 - val_loss: 113675960.0000\n",
      "Epoch 1323/200000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 373650944.0000 - val_loss: 113635600.0000\n",
      "Epoch 1324/200000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 373277312.0000 - val_loss: 113595832.0000\n",
      "Epoch 1325/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 372905696.0000 - val_loss: 113556672.0000\n",
      "Epoch 1326/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 372536128.0000 - val_loss: 113518096.0000\n",
      "Epoch 1327/200000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 372168512.0000 - val_loss: 113480096.0000\n",
      "Epoch 1328/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 371802944.0000 - val_loss: 113442656.0000\n",
      "Epoch 1329/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 371439328.0000 - val_loss: 113405784.0000\n",
      "Epoch 1330/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 371077728.0000 - val_loss: 113369488.0000\n",
      "Epoch 1331/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 370718080.0000 - val_loss: 113333744.0000\n",
      "Epoch 1332/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 370360384.0000 - val_loss: 113298552.0000\n",
      "Epoch 1333/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 370004672.0000 - val_loss: 113263928.0000\n",
      "Epoch 1334/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 369650912.0000 - val_loss: 113229832.0000\n",
      "Epoch 1335/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 369299008.0000 - val_loss: 113196288.0000\n",
      "Epoch 1336/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 368949120.0000 - val_loss: 113163296.0000\n",
      "Epoch 1337/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 368601024.0000 - val_loss: 113130808.0000\n",
      "Epoch 1338/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 368255008.0000 - val_loss: 113098848.0000\n",
      "Epoch 1339/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 367910752.0000 - val_loss: 113067384.0000\n",
      "Epoch 1340/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 367568416.0000 - val_loss: 113036472.0000\n",
      "Epoch 1341/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 367228032.0000 - val_loss: 113006040.0000\n",
      "Epoch 1342/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 366889376.0000 - val_loss: 112976160.0000\n",
      "Epoch 1343/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 366552736.0000 - val_loss: 112946760.0000\n",
      "Epoch 1344/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 366217888.0000 - val_loss: 112917856.0000\n",
      "Epoch 1345/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 365884832.0000 - val_loss: 112889488.0000\n",
      "Epoch 1346/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 365553600.0000 - val_loss: 112861552.0000\n",
      "Epoch 1347/200000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 365224192.0000 - val_loss: 112834144.0000\n",
      "Epoch 1348/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 364896640.0000 - val_loss: 112807192.0000\n",
      "Epoch 1349/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 364570880.0000 - val_loss: 112780736.0000\n",
      "Epoch 1350/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 364246848.0000 - val_loss: 112754728.0000\n",
      "Epoch 1351/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 363924672.0000 - val_loss: 112729168.0000\n",
      "Epoch 1352/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 363604224.0000 - val_loss: 112704056.0000\n",
      "Epoch 1353/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 363285536.0000 - val_loss: 112679432.0000\n",
      "Epoch 1354/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 362968608.0000 - val_loss: 112655224.0000\n",
      "Epoch 1355/200000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 362653344.0000 - val_loss: 112631536.0000\n",
      "Epoch 1356/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 362339808.0000 - val_loss: 112608288.0000\n",
      "Epoch 1357/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 362027904.0000 - val_loss: 112585512.0000\n",
      "Epoch 1358/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 361717728.0000 - val_loss: 112563184.0000\n",
      "Epoch 1359/200000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 361409280.0000 - val_loss: 112541288.0000\n",
      "Epoch 1360/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 361102464.0000 - val_loss: 112519864.0000\n",
      "Epoch 1361/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 360797344.0000 - val_loss: 112498864.0000\n",
      "Epoch 1362/200000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 360493888.0000 - val_loss: 112478288.0000\n",
      "Epoch 1363/200000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 360192096.0000 - val_loss: 112458160.0000\n",
      "Epoch 1364/200000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 359891904.0000 - val_loss: 112438432.0000\n",
      "Epoch 1365/200000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 359593344.0000 - val_loss: 112419112.0000\n",
      "Epoch 1366/200000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 359296416.0000 - val_loss: 112400224.0000\n",
      "Epoch 1367/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 359001120.0000 - val_loss: 112381736.0000\n",
      "Epoch 1368/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 358707520.0000 - val_loss: 112363640.0000\n",
      "Epoch 1369/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 358415424.0000 - val_loss: 112345944.0000\n",
      "Epoch 1370/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 358124896.0000 - val_loss: 112328656.0000\n",
      "Epoch 1371/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 357835968.0000 - val_loss: 112311768.0000\n",
      "Epoch 1372/200000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 357548704.0000 - val_loss: 112295264.0000\n",
      "Epoch 1373/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 357262880.0000 - val_loss: 112279152.0000\n",
      "Epoch 1374/200000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 356978528.0000 - val_loss: 112263424.0000\n",
      "Epoch 1375/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 356695904.0000 - val_loss: 112248064.0000\n",
      "Epoch 1376/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 356414688.0000 - val_loss: 112233064.0000\n",
      "Epoch 1377/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 356135040.0000 - val_loss: 112218448.0000\n",
      "Epoch 1378/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 355856864.0000 - val_loss: 112204192.0000\n",
      "Epoch 1379/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 355580256.0000 - val_loss: 112190280.0000\n",
      "Epoch 1380/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 355305120.0000 - val_loss: 112176688.0000\n",
      "Epoch 1381/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 355031456.0000 - val_loss: 112163480.0000\n",
      "Epoch 1382/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 354759296.0000 - val_loss: 112150584.0000\n",
      "Epoch 1383/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 354488576.0000 - val_loss: 112137984.0000\n",
      "Epoch 1384/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 354219360.0000 - val_loss: 112125712.0000\n",
      "Epoch 1385/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 353951616.0000 - val_loss: 112113768.0000\n",
      "Epoch 1386/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 353685280.0000 - val_loss: 112102136.0000\n",
      "Epoch 1387/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 353420384.0000 - val_loss: 112090864.0000\n",
      "Epoch 1388/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 353156960.0000 - val_loss: 112079864.0000\n",
      "Epoch 1389/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 352894912.0000 - val_loss: 112069184.0000\n",
      "Epoch 1390/200000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 352634368.0000 - val_loss: 112058816.0000\n",
      "Epoch 1391/200000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 352375136.0000 - val_loss: 112048776.0000\n",
      "Epoch 1392/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 352117376.0000 - val_loss: 112038992.0000\n",
      "Epoch 1393/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 351860960.0000 - val_loss: 112029496.0000\n",
      "Epoch 1394/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 351605856.0000 - val_loss: 112020328.0000\n",
      "Epoch 1395/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 351352224.0000 - val_loss: 112011432.0000\n",
      "Epoch 1396/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 351099968.0000 - val_loss: 112002800.0000\n",
      "Epoch 1397/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 350849056.0000 - val_loss: 111994480.0000\n",
      "Epoch 1398/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 350599424.0000 - val_loss: 111986424.0000\n",
      "Epoch 1399/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 350351232.0000 - val_loss: 111978640.0000\n",
      "Epoch 1400/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 350104224.0000 - val_loss: 111971112.0000\n",
      "Epoch 1401/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 349858624.0000 - val_loss: 111963880.0000\n",
      "Epoch 1402/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 349614304.0000 - val_loss: 111956880.0000\n",
      "Epoch 1403/200000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 349371328.0000 - val_loss: 111950136.0000\n",
      "Epoch 1404/200000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 349129632.0000 - val_loss: 111943656.0000\n",
      "Epoch 1405/200000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 348889184.0000 - val_loss: 111937472.0000\n",
      "Epoch 1406/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 348650080.0000 - val_loss: 111931512.0000\n",
      "Epoch 1407/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 348412128.0000 - val_loss: 111925816.0000\n",
      "Epoch 1408/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 348175424.0000 - val_loss: 111920352.0000\n",
      "Epoch 1409/200000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 347940096.0000 - val_loss: 111915112.0000\n",
      "Epoch 1410/200000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 347705920.0000 - val_loss: 111910128.0000\n",
      "Epoch 1411/200000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 347473024.0000 - val_loss: 111905384.0000\n",
      "Epoch 1412/200000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 347241376.0000 - val_loss: 111900904.0000\n",
      "Epoch 1413/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 347010880.0000 - val_loss: 111896616.0000\n",
      "Epoch 1414/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 346781632.0000 - val_loss: 111892560.0000\n",
      "Epoch 1415/200000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 346553632.0000 - val_loss: 111888712.0000\n",
      "Epoch 1416/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 346326816.0000 - val_loss: 111885096.0000\n",
      "Epoch 1417/200000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 346101152.0000 - val_loss: 111881696.0000\n",
      "Epoch 1418/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 345876736.0000 - val_loss: 111878496.0000\n",
      "Epoch 1419/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 345653440.0000 - val_loss: 111875488.0000\n",
      "Epoch 1420/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 345431328.0000 - val_loss: 111872704.0000\n",
      "Epoch 1421/200000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 345210336.0000 - val_loss: 111870104.0000\n",
      "Epoch 1422/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 344990528.0000 - val_loss: 111867696.0000\n",
      "Epoch 1423/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 344771872.0000 - val_loss: 111865480.0000\n",
      "Epoch 1424/200000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 344554336.0000 - val_loss: 111863456.0000\n",
      "Epoch 1425/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 344337920.0000 - val_loss: 111861584.0000\n",
      "Epoch 1426/200000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 344122624.0000 - val_loss: 111859896.0000\n",
      "Epoch 1427/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 343908416.0000 - val_loss: 111858392.0000\n",
      "Epoch 1428/200000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 343695392.0000 - val_loss: 111857088.0000\n",
      "Epoch 1429/200000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 343483392.0000 - val_loss: 111855960.0000\n",
      "Epoch 1430/200000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 343272448.0000 - val_loss: 111854960.0000\n",
      "Epoch 1431/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 343062656.0000 - val_loss: 111854152.0000\n",
      "Epoch 1432/200000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 342853920.0000 - val_loss: 111853496.0000\n",
      "Epoch 1433/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 342646272.0000 - val_loss: 111852968.0000\n",
      "Epoch 1434/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 342439680.0000 - val_loss: 111852624.0000\n",
      "Epoch 1435/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 342234144.0000 - val_loss: 111852432.0000\n",
      "Epoch 1436/200000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 342029568.0000 - val_loss: 111852392.0000\n",
      "Epoch 1437/200000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 341826144.0000 - val_loss: 111852496.0000\n",
      "Epoch 1438/200000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 341623712.0000 - val_loss: 111852752.0000\n",
      "Epoch 1439/200000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 341422272.0000 - val_loss: 111853144.0000\n",
      "Epoch 1440/200000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 341221920.0000 - val_loss: 111853664.0000\n",
      "Epoch 1441/200000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 341022560.0000 - val_loss: 111854336.0000\n",
      "Epoch 1442/200000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 340824288.0000 - val_loss: 111855104.0000\n",
      "Epoch 1443/200000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 340626912.0000 - val_loss: 111856024.0000\n",
      "Epoch 1444/200000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 340430624.0000 - val_loss: 111857088.0000\n",
      "Epoch 1445/200000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 340235264.0000 - val_loss: 111858264.0000\n",
      "Epoch 1446/200000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 340040896.0000 - val_loss: 111859576.0000\n",
      "Epoch 1447/200000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 339847424.0000 - val_loss: 111861056.0000\n",
      "Epoch 1448/200000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 339654976.0000 - val_loss: 111862632.0000\n",
      "Epoch 1449/200000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 339463424.0000 - val_loss: 111864336.0000\n",
      "Epoch 1450/200000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 339272800.0000 - val_loss: 111866152.0000\n",
      "Epoch 1451/200000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 339083104.0000 - val_loss: 111868112.0000\n",
      "Epoch 1452/200000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 338894368.0000 - val_loss: 111870152.0000\n",
      "Epoch 1453/200000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 338706496.0000 - val_loss: 111872336.0000\n",
      "Epoch 1454/200000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 338519584.0000 - val_loss: 111874664.0000\n",
      "Epoch 1455/200000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 338333536.0000 - val_loss: 111877104.0000\n",
      "Epoch 1456/200000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 338148384.0000 - val_loss: 111879656.0000\n",
      "Epoch 1457/200000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 337964128.0000 - val_loss: 111882304.0000\n",
      "Epoch 1458/200000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 337780736.0000 - val_loss: 111885032.0000\n",
      "Epoch 1459/200000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 337598336.0000 - val_loss: 111887848.0000\n",
      "Epoch 1460/200000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 337416672.0000 - val_loss: 111890768.0000\n",
      "Epoch 1461/200000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 337235872.0000 - val_loss: 111893792.0000\n",
      "Epoch 1462/200000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 337055936.0000 - val_loss: 111896952.0000\n",
      "Epoch 1463/200000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 336876864.0000 - val_loss: 111900208.0000\n",
      "Epoch 1464/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 336698688.0000 - val_loss: 111903552.0000\n",
      "Epoch 1465/200000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 336521280.0000 - val_loss: 111906992.0000\n",
      "Epoch 1466/200000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 336344672.0000 - val_loss: 111910472.0000\n",
      "Epoch 1467/200000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 336168928.0000 - val_loss: 111914048.0000\n",
      "Epoch 1468/200000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 335994048.0000 - val_loss: 111917664.0000\n",
      "Epoch 1469/200000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 335819968.0000 - val_loss: 111921384.0000\n",
      "Epoch 1470/200000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 335646720.0000 - val_loss: 111925184.0000\n",
      "Epoch 1471/200000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 335474208.0000 - val_loss: 111929040.0000\n",
      "Epoch 1472/200000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 335302496.0000 - val_loss: 111932984.0000\n",
      "Epoch 1473/200000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 335131680.0000 - val_loss: 111936984.0000\n",
      "Epoch 1474/200000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 334961600.0000 - val_loss: 111941016.0000\n",
      "Epoch 1475/200000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 334792288.0000 - val_loss: 111945096.0000\n",
      "Epoch 1476/200000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 334623744.0000 - val_loss: 111949216.0000\n",
      "Epoch 1477/200000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 334455968.0000 - val_loss: 111953416.0000\n",
      "Epoch 1478/200000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 334289024.0000 - val_loss: 111957696.0000\n",
      "Epoch 1479/200000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 334122752.0000 - val_loss: 111962000.0000\n",
      "Epoch 1480/200000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 333957280.0000 - val_loss: 111966328.0000\n",
      "Epoch 1481/200000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 333792544.0000 - val_loss: 111970680.0000\n",
      "Epoch 1482/200000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 333628544.0000 - val_loss: 111975096.0000\n",
      "Epoch 1483/200000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 333465280.0000 - val_loss: 111980512.0000\n",
      "Epoch 1484/200000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 333302816.0000 - val_loss: 111986632.0000\n",
      "Epoch 1485/200000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 333140960.0000 - val_loss: 111992792.0000\n",
      "Epoch 1486/200000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 332979968.0000 - val_loss: 111998976.0000\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "# validation_split : 주어진 데이터에서 사용할 검증데이터 비율\n",
    "history = model.fit(X_train, y_train, epochs=200000, batch_size=10000,\n",
    "                    validation_data=[X_test, y_test], callbacks=[call1, call2, call3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70296a74-3769-4960-8660-6286ceade680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 리스트를 추출한다.\n",
    "loss_list = history.history['loss']\n",
    "val_loss_list = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2217eef9-424d-4b63-af7b-4bbc955d48b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 586,
       "width": 1150
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실율 그래프\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(loss_list[:-50], label='loss')\n",
    "plt.plot(val_loss_list[:-50], label = 'val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
